---
title: "Modelado"
subtitle: "Proyecto Final"
author: "Alfredo Lefranc Flores, Cynthia Raquel Valdivia Tirado, Rafael Sandoval Fernández, Marco Antonio Ramos Juárez y Francisco Velazquez Guadarrama"
date: "2021"
output:
  html_document:
    graphics: yes
    urlcolor: blue
    theme: spacelab
    df_print: paged
    toc: yes
    toc_depth: '3'
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE, warning=FALSE,
                      fig.width = 7, fig.height = 4, fig.align = "right",tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

```{r, include=FALSE}

packages <- c(
  "tidyverse", "data.table", "broom",
  "knitr", "naniar", "lubridate",
  "RCT", "splitstackshape", "magrittr",
  "kableExtra", "stargazer",
  "gridExtra", "igraph", "tidygraph",
  "networkD3","visNetwork",
  "reshape2","data.table","DT",
  "ranger", "parallel", "Matrix", "gamlr",
  "mltools","xgboost"
  )


# instala los paquetes que no se tengan
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# cargar paquetes
lapply(packages,
       library,
       character.only = TRUE)

# desactiva notación científica       
options(scipen = 999)


```


Cargamos la base y revisamos sus variables. Notamos outliers en la variable de duración. Los truncamos al 99.9% para que no afecten las predicciones de nuestros modelos.

```{r}
load("base_modelo.RData")
load("base_trips.RData")
summary(trips_filter)

# funcion
winsorize <- function(vector, list_lower_upper){

  upper <- quantile(vector, probs = list_lower_upper)[[2]]

  lower <- quantile(vector, probs = list_lower_upper)[[1]]

  vector <- replace(vector, vector>upper, upper) %>% replace(vector<lower, lower)

  return(vector)
}

# aplicamos la función para truncar outliers
trips_filter$duration <- trips_filter$duration %>% winsorize(c(0,0.999))


```

Para poder aumentar la eficiencia de los modelos, transformamos la base a formato ancho. Esto lo hacemos para dos variables con muchas categorías, las estaciones de salida y llegada.

```{r, cache=TRUE}

# formato wide de start y end station
stations_wide <- trips_filter %>%
  select("seq_id","strt_statn","end_statn") %>% as.data.table() %>%
  one_hot()

trips_filter <- inner_join(trips_filter,stations_wide, by="seq_id")

trips_filter <- trips_filter %>%
  select(-c("strt_statn","end_statn")) %>%
  arrange(seq_id)

```


## Modelos

Primero separamos la base de validación y de entrenamiento. Usamos una división 80-20. Para esto decidimos estratificar por días y no por viajes. De esta manera tenemos un panorama completo de los días en entrenamiento, y evaluaremos en días nuevos en la base de validación. Esto nos parece un ejercicio más realista dados los objetivos del negocio.

Para tener un balance en nuestros sets de entrenamiento y validación, estratificamos por año, mes y día de la semana. Una vez hecha la estratificación, verificamos el balance entre entrenamiento y validación.

```{r}

# para ello, nos fijamos en todos los días donde tenemos viajes
dates <- trips_filter %>% select(c("start_date","start_month","start_weekday",
                                   "start_year")) %>% unique()


# estratificamos
treat_id <- treatment_assign(data = dates, share_control = 0.2,
                    n_t = 1,
                    strata_varlist = c("start_month",
                                       "start_weekday",
                                       "start_year"),
                    missfits = "global",
                    seed = 2021, key = "start_date")$data

# pegamos la variable que asigna tratamiento a la base
trips_filter <- left_join(trips_filter,treat_id,by=("start_date"))
trips_filter <- trips_filter %>% select(-c("strata","missfit"))
```

Al hacer la separación, nos cercioramos de que exista balance entre ambas bases. Esto lo hacemos con prubas t y F para las variables numéricas.

```{r}
summary(trips_filter$treat)
# el share control se mantiene estable

# revisamos balance de clases no estratificadas

# pruebas t en las numéricas
is_num <- lapply(trips_filter,function(x) is.numeric(x))

trips_num <- trips_filter %>% select((names(is_num[is_num==TRUE])))

balance_t<-balance_table(data = sample_n(trips_num,10000),
                         treatment = "treat")
balance_t$p_value1 <- balance_t$p_value1 %>% round(3)

#filtramos las variables donde se rechaza la hipótesis de igualdad al 10%
balance_t_filter<- balance_t %>% filter(p_value1 < .1)
datatable(balance_t_filter, options = list(pageLength = 5))
```

37 variables muestran desbalance, dummies de estaciones y edad. La significancia conjunta no se rechaza. Por ende, consideramos que no es preocupante.


```{r}
# pruebas F
balance_f<-balance_regression(data = sample_n(trips_num,100000),
                              treatment = "treat")

kable(balance_f$F_test, align = 'c',booktabs=T,digits = 2,
        caption = "Regresión de balance",
      col.names = c("Estadístico", "Valor")) %>%
  kable_styling(position = "center")
```

Ahora procedemos a separar las bases en entrenamiento y validación. Acotamos la de entrenamiento para tener una muestra más pequeña. Convertimos las bases de covariables en matrices ralas.

```{r}

train <- trips_filter[trips_filter$treat==1,]

y_train <- train$duration[train$treat==1]

train <-  train %>% select(-c("treat","seq_id","duration"))

sparse_train <- sparse.model.matrix(~.+0, data = train)

# validacion
test <- trips_filter[trips_filter$treat==0,] %>%
  select(-c("treat","seq_id","duration"))

sparse_test <- sparse.model.matrix(~.+0, data = test)

y_test <- trips_filter[trips_filter$treat==0,] %>%select(c("seq_id","duration"))

```


#### Lasso

Primero probamos un LASSO con Cross Validation.

```{r}
lasso <- cv.gamlr(x = sparse_train,
                  y = y_train,
                  verb = T,
                  nfold = 10)

plot(lasso)

plot(lasso$gamlr)

coef(lasso, select="min", k=2, corrected=T)

# Lambda óptima
lambda_optima<- colnames(coef(lasso, select="min"))
lasso$gamlr$lambda[lambda_optima]

# predicciones del lasso
y_test$pred_lasso <- predict(lasso,
                             newdata = sparse_test,
                             select = "min") %>% drop()
```

Guardamos las predicciones del modelo.

#### Random Forest

El segundo modelo que deseamos probar es el random forest. Probamos con distintas B, desde 100 hasta 700, siendo 500 el óptimo por reducir el error OOB.

Por razones de tiempo, corrimos el modelo sobre una submuestra de entrenamiento. Nos aseguramos que ésta respetara la estratificación antes descrita.

```{r}

# ajuste del set de entrenamiento
dates <- train %>% select(c("start_date","start_month","start_weekday",
                                   "start_year")) %>% unique()

# estratificamos
treat_id <- treatment_assign(data = dates, share_control = 0.75,
                    n_t = 1,
                    strata_varlist = c("start_month",
                                       "start_weekday",
                                       "start_year"),
                    missfits = "global",
                    seed = 2021, key = "start_date")$data

# pegamos la variable que asigna tratamiento a la base
train_cf <- left_join(cbind(train,y_train),
                      treat_id,
                      by=("start_date"))
train_cf <- train_cf %>% select(-c("strata","missfit"))

# subset de la base para los días elegidos
train_cf <- train_cf[train_cf$treat==1,]
y_train_cf <- train_cf$y_train[train_cf$treat==1]

train_cf <-  train_cf %>% select(-c("treat","y_train"))

sparse_train_cf <- sparse.model.matrix(~.+0, data = train_cf)
```

Una vez hechos los ajustes, corremos el RF.

```{r}
# para correr modelos en paralelo
cores <- detectCores()
cl<-makeCluster(cores)
inicio<-Sys.time()

# c(100,200,350,500,700)
random_forest <- map(c(500),
                     function(z)
                       ranger(y=y_train_cf,
                              x=sparse_train_cf,
                              num.trees = z,
                              mtry = ncol(train) %>% sqrt() %>% floor(),
                              min.node.size = 1,
                              importance = 'impurity',
                              status.variable.name = 1)
                     )


(tiempo<-Sys.time() - inicio)
stopCluster(cl)

error_prediccion<-tibble(trees = c(500),
                         oob_error = map_dbl(random_forest, ~.$prediction.error))

# error medido en horas
#ggplot(error_prediccion, aes(trees, oob_error/60)) +
#  geom_point() +
#  geom_path() +
#  theme_bw()



df_imp <- data.frame(names=random_forest[[1]][["variable.importance"]] %>% names(),
           importance=random_forest[[1]][["variable.importance"]]) %>%
  arrange(-importance)


# predicciones OOS
y_test$pred_rf<-predict(random_forest[[1]], data = sparse_test)$predictions

```

## XGB

Finalmente, probamos un XGB. Entrenamos el modelo y unimos las predicciones a la base de evaluación.

```{r}
# Preparar la base de entrenamiento y de validación
dtrain <- xgb.DMatrix(sparse_train, label = y_train)
dtest <- xgb.DMatrix(sparse_test, label = y_test$duration)
watchlist <- list(train = dtrain, eval = dtest)

# Entrenamiento del modelo
param <- list(max_depth = 5, learning_rate = 0.06,
              objective = "reg:squarederror",
              eval_metric = "rmse",
              subsample = 0.85,
              colsample_bytree = 0.7)
xgb_model <- xgb.train(params = param,
                       dtrain,
                       early_stopping_rounds = 10,
                       nrounds = 100,
                       watchlist)

# Predicción
y_test$pred_xgb <- predict(xgb_model, sparse_test)

```

# Desempeño de modelos
```{r}
#PREPROCESAMIENTO

# cargar la base completa
load("base_trips.RData")

#creo base para deployment
deployment<-cbind(y_test,test)
timestamps<-trips%>% select(start_DateTime,end_DateTime,seq_id,end_date)

#formato timestamp
timestamps$start_DateTime<-strptime(timestamps$start_DateTime, "%m/%d/%Y %H:%M:%OS")
timestamps$end_DateTime<-strptime(timestamps$end_DateTime, "%m/%d/%Y %H:%M:%OS")

#creo predicciones de horrario de llega con base en la predicción del tiempo de duración
dep<-left_join(deployment,timestamps, by = c("seq_id" ))
dep<- dep %>% mutate(end_DateTime_predi=start_DateTime+pred_lasso)
uniquedates<-as.data.frame(unique(dep$start_date))
stations<-trips %>% select(seq_id,strt_statn)
dep<-left_join(dep,stations, by = c("seq_id" ))


```

## Medidas tradicionales

Como medidas tradicionales, podemos compara ambos modelos midiendo el tamaño de los residuales. Al ser la variable objetico numérica,  podemos emplear el R^2.

```{r}
#r2 rf
sum((dep$pred_lasso-mean(dep$duration))^2)/sum((dep$duration-mean(dep$duration))^2)

#residuals rf

# MSE
# LASSO
sqrt(sum(dep$pred_lasso-dep$duration)^2)/(nrow(dep)*60)
# RF
sqrt(sum(dep$pred_rf-dep$duration)^2)/(nrow(dep)*60)

# XGB
sqrt(sum(dep$pred_xgb-dep$duration)^2)/(nrow(dep)*60)

```

## Medidas alternativas

#### Predicciones y flujo de biciletas por estación

Para mostrar el desempeño de los modelos, modelaremos los flujos de bicicleta de nuestra base de validación pero ahora en lugar de usar la duración del viaje real, usaremos la predicha. Para ellos crearemos primero una base de datos que compare los flujos de viaje cada 10 minutos entre lo que en realidad pasó y lo que predice nuestro modelo.



```{r}
#LOOP para crear bases de datos con predicciones de viajes

#CREO LA BASE DE DATOS DE CADA 10 MINUTOS DEL SET TRAINING QUE VA ASERVIR COMO EL ESQUELETO
start.date <- strptime(paste(uniquedates[1,1],"0:0:0"), "%Y-%m-%d %H:%M:%OS")
start.date <- format(start.date, "%Y-%m-%d %H:%M:%OS")
end.date <- strptime(paste(uniquedates[1,1],"23:50:0"), "%Y-%m-%d %H:%M:%OS")
end.date <- format(end.date, "%Y-%m-%d %H:%M:%OS")
dates<-as.data.frame(seq(as.POSIXlt(start.date),as.POSIXlt(end.date), by = 10*60))
dates$date<-uniquedates[1,1]

for (i in 2:nrow(uniquedates))
{
start.date <- strptime(paste(uniquedates[i,1],"0:0:0"), "%Y-%m-%d %H:%M:%OS")
start.date <- format(start.date, "%Y-%m-%d %H:%M:%OS")
end.date <- strptime(paste(uniquedates[i,1],"23:50:0"), "%Y-%m-%d %H:%M:%OS")
end.date <- format(end.date, "%Y-%m-%d %H:%M:%OS")
dates_b<-as.data.frame(seq(as.POSIXlt(start.date),as.POSIXlt(end.date), by = 10*60))
dates_b$date<-uniquedates[i,1]
dates <- rbind(dates,dates_b)
}
names(dates)<-c("horario","fecha")

#MULTIPLICO LA BASE POR LA CANTIDAD DE ESTACIONES

unique_strt_stion<-as.data.frame(unique(dep$strt_statn))

dates$strt_statn<-unique_strt_stion[i,1]
dates_agr<-dates
for (i in 2:nrow(unique_strt_stion))
{
dates$strt_statn<-unique_strt_stion[i,1]
dates_agr <- rbind(dates_agr,dates)
}

#Esta es mi plantilla en la que vaciaré todos los datos
plantilla<-separate(dates_agr, horario, into = c("date","hour"), sep = " (?=[^ ]+$)")
plantilla$hour<-as.ITime(plantilla$hour)
plantilla$date<-NULL
plantilla <- plantilla %>% rename (date=fecha)
```


```{r}
#SEGMENTO LA BASE EN INTERVALOS DE TIEMPO PARA VER LAS SALIDAS DE BICIS
v1<-dep%>% mutate(interval_min = lubridate::minute(start_DateTime) %/% 10,
                 interval_hour = lubridate::hour(start_DateTime) %/% 1  ) %>% group_by(start_date, interval_min,interval_hour,strt_statn)%>%
    summarise(count_salida = n())%>%rename(date=start_date)
v1<-v1%>% mutate(min=paste(interval_min,"0", sep = ""), hour=paste(interval_hour,min, sep = ":"))
v1$interval_min<-NULL
v1$interval_hour<-NULL
v1$min<-NULL
v1$hour<-as.ITime(v1$hour)

```

```{r}

#SEGMENTO LA BASE EN INTERVALOS DE TIEMPO PARA VER LAS LLEGADAS DE LAS BICIS CON DATOS REALES
v2<-dep%>% mutate(interval_min = lubridate::minute(end_DateTime) %/% 10,
                 interval_hour = lubridate::hour(end_DateTime) %/% 1  ) %>% group_by(end_date, interval_min,interval_hour,strt_statn)%>%
    summarise(count_llegada_real = n())%>%rename(date=end_date)
v2<-v2%>% mutate(min=paste(interval_min,"0", sep = ""), hour=paste(interval_hour,min, sep = ":"))
v2$interval_min<-NULL
v2$interval_hour<-NULL
v2$min<-NULL
v2$hour<-as.ITime(v2$hour)
```

```{r}

#SEGMENTO LA BASE EN INTERVALOS DE TIEMPO PARA VER LAS LLEGADAS DE LAS BICIS CON DATOS PREDECIDOS
dep$end_date_pred <- as.Date(dep$end_DateTime_predi, '%m/%d/%Y')

v3<-dep%>% mutate(interval_min = lubridate::minute(end_DateTime_predi) %/% 10,
                 interval_hour = lubridate::hour(end_DateTime_predi) %/% 1  ) %>% group_by(end_date_pred, interval_min,interval_hour,strt_statn)%>%
    summarise(count_llegada_pred = n())%>%rename(date=end_date_pred)
v3<-v3%>% mutate(min=paste(interval_min,"0", sep = ""), hour=paste(interval_hour,min, sep = ":"))
v3$interval_min<-NULL
v3$interval_hour<-NULL
v3$min<-NULL
v3$hour<-as.ITime(v3$hour)
```


```{r}
#Creo la base final para mostrar

plantilla_llena<-merge(x = plantilla, y = v1, by = c("hour", "date","strt_statn"), all.x = TRUE)
plantilla_llena$count_salida[is.na(plantilla_llena$count_salida)] <- 0

plantilla_llena<-merge(x = plantilla_llena, y = v2, by = c("hour", "date","strt_statn"), all.x = TRUE)
plantilla_llena$count_llegada_real[is.na(plantilla_llena$count_llegada_real)] <- 0

plantilla_llena<-merge(x = plantilla_llena, y = v3, by = c("hour", "date","strt_statn"), all.x = TRUE)
plantilla_llena$count_llegada_pred[is.na(plantilla_llena$count_llegada_pred)] <- 0

#Agrego columna de acumulados

plantilla_llena$acum_salida <- ave(plantilla_llena$count_salida, plantilla_llena$strt_statn,plantilla_llena$date, FUN=cumsum)

plantilla_llena$acum_llegada_real <- ave(plantilla_llena$count_llegada_real, plantilla_llena$strt_statn,plantilla_llena$date, FUN=cumsum)

plantilla_llena$acum_llegada_pred <- ave(plantilla_llena$count_llegada_pred, plantilla_llena$strt_statn,plantilla_llena$date, FUN=cumsum)

#trial<-plantilla_llena%>%filter((date=="2011-10-18"|date== "2011-08-01") & strt_statn==3)

```

En la siguiente tabla se muestran los flujos acumulados de bicicletas que salen y llegan (con datos reales y predecidos). Por motivos de costo computacional, solamente mostramos algunos días completos para algunas estaciones aleatorias.Por favor haga click primer primero en estación y luego en fecha para que la tabla esté ordenada de acuerdo a la hora:

```{r}
#Deployment de las bases de datos en una app (selecciono de manera aleatoria algunas debido al peso computacional)

random_stations<-sample(3:133, 3, replace=FALSE)

output<-plantilla_llena%>% filter(strt_statn%in%random_stations )
#output<-sample_n(plantilla_llena, 1000)
output<- output%>% select(date,hour, strt_statn,acum_salida,acum_llegada_real,acum_llegada_pred)
names(output)<- c("Fecha","Hora","Estación","Salidas","Llegadas(real)","Llegadas(modelo)")
datatable(output,
          options = list(pageLength = 15))
```

### Error promedio a la hora de corte

Derivado de estas tablas, se nos ocurrió que una forma muy util de probar el desempeño de los modelos es a través del error del flujo en determinado punto del día. Esto pensando en que en las empresas de este tipo, hay un punto de corte en el que las estaciones se tienen que llenar o vaciar de bicicletas. Para este ejemplo, propusimos un punto de corte a las 12 de la noche, pero bien podría ser en la madrugada, o en la tarde. En la siguiente tabla se muestra el error promedio en el cálculo del flujo de bicis para la hora de corte.

```{r}
#medidas alternativas de error, cuantas bicis nos quedamos atrás en promedio
#ERROR EN LA CANTIDAD DE BICI AL FINAL DEL DÍA
plantilla_llena$hour<-as.character(plantilla_llena$hour)
bici_error<-plantilla_llena%>% filter(hour=='23:50:00') %>% mutate (error=abs(acum_llegada_real-acum_llegada_pred)) %>% group_by(strt_statn) %>% select(strt_statn,error) %>%
    summarise(error_medio = mean((error)))

datatable(bici_error,options = list(
  pageLength = 10, autoWidth = TRUE
), colnames = c("Estación","Error medio al final del día"))


```


#Conclusiones


Con estos resultados es posible optimizar la gestión del servicio de bicicletas otorgado por la empresa Wheelie Wonka. Este pronóstico preciso sirve de guía para que los pasajeros puedan organizar mejor su hora de salida y las rutas de desplazamiento. Además, es beneficioso para el proveedor de servicios de bicicletas compartidas Wheelie Wonka en términos de mejorar la satisfacción de sus clientes y organizar con efectividad el horario de entrega y distribución de bicicletas y así eficientar sus recursos y disminuir pérdidas.
