---
title: "Comprensión del Negocio y de los Datos"
subtitle: "Proyecto Final"
author: "Alfredo Lefranc Flores, Cynthia Raquel Valdivia Tirado, Rafael Sandoval Fernández, Marco Antonio Ramos Juárez y Francisco Velazquez Guadarrama"
date: "2021"
output:
  html_document:
    graphics: yes
    urlcolor: blue
    theme: spacelab
    df_print: paged
    toc: yes
    toc_depth: '3'
    toc_float: true
---



```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE, warning=FALSE,
                      fig.width = 7, fig.height = 4, fig.align = "right",tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

```{r, include=FALSE}

packages <- c(
  "tidyverse", "data.table", "broom",
  "knitr", "naniar", "lubridate",
  "RCT", "splitstackshape", "magrittr",
  "kableExtra", "stargazer",
  "gridExtra", "igraph", "tidygraph",
  "reshape2", "ggthemes", "grid",
  "geosphere","data.table","DT",
  "reshape2","ggthemes","grid","heatmaply",
  "ggraph","GGally"
  )

# instala los paquetes que no se tengan
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# cargar paquetes
lapply(packages,
       library,
       character.only = TRUE)

# desactiva notación científica       
options(scipen = 999)


```

## Planteamiento del Problema

Al conectar una multiplicidad de orígenes y destinos, el transporte público ha probado ser un motor del desarrollo económico urbano, además de potencialmente impactar los ámbitos de salud y seguridad pública, congestión vehicular, y la inclusión social. En este contexto, los sistemas de bicicletas compartidas han ofrecido una alternativa a las opciones de transporte en redes urbanas altamente complejas.
Como tal, cualquier empresa de bicicletas compartidas debe ser capaz de ofrecer a sus usuarios una opción eficaz para trasladarse, es decir, práctica y accesible. La empresa Wheelie Wonka no debe ser la excepción.

Sin embargo, tal como es el caso de los flujos de tráfico, las bicicletas enfrentan el problema de demandas asimétricas en tiempo y espacio. Esto puede significar un problema en la medida en que la infraestructura de la red de bicicletas limite a los usuarios en momentos de alta demanda, y también que el uso y desplazamiento de las bicicletas en un momento dado no corresponda a las necesidades de los usuarios siguientes, creando excesos de oferta y de demanda en distintas zonas de Boston.

En Boston, para el servicio de bicicletas compartidas, existen estaciones designadas para su  almacenamiento, por lo que la estación podría estar vacía o saturada en diferentes periodos. Los operadores de bicicletas compartidas generalmente redistribuyen las bicicletas entre las diferentes estaciones; no obstante, esta distribución desequilibrada puede conllevar a pérdidas para la empresa, al estar utilizando recursos humanos innecesarios, y perjudicar a los usuarios en su acceso al servicio, dado que podría generarse una situación de falta de disponibilidad de bicicletas o a la saturación de éstas. Por lo tanto, predecir un número exacto de bicicletas disponibles en las estaciones es importante.

Existen factores que pueden incidir en las tendencias de los viajes de los pasajeros que son relevantes para determinar la disponibilidad de las bicicletas, como la duración del viaje, la hora del día (horas punta), el día de la semana, el clima, la edad del pasajero, su género, las estaciones del año, las vacaciones, la popularidad de la ubicación, entre otros. Por tanto, mejores datos podrían ayudar a hacer una mejor predicción.

En este contexto, la ciencia de datos ofrece una solución muy atractiva. Mediante el análisis computacional del uso de las bicicletas, es posible reconocer patrones y predecir la disponibilidad de bicicletas en un lugar y momento específicos. Esto puede ayudar a la empresa Wheelie Wonka en dos sentidos.

1) Proveer al usuario de información con la cual pueda tomar decisiones óptimas de transporte.
2) Poder hacer ajustes en la distribución de las bicicletas a lo largo de las cicloestaciones para prevenir escaseces y excesos en el sistema.

Estos puntos seguramente aumentarían la satisfacción del usuario, disminuirían las pérdidas en eficiencia, y permitirían un mayor uso del servicio, lo cual sólo podría traer beneficios a Wheelie Wonka.

En este sentido, los objetivos específicos de este proyecto son los siguientes:

a. Poder pronosticar la duración de los viajes.
b. Entender los factores que tienen un impacto en la duración de los viajes e identificar patrones geográficos en los datos.
c. Estimar el número de bicicletas por estación en ventanas de 10 minutos.

Estos tres puntos se verán reflejados en nuestro entregable final, el producto para los clientes: un dashboard que modele el flujo de bicicletas en las estaciones para un día de la semana dado, en intervalos de 10 minutos.

El estudio comienza con la creación y transformación de variables, así como con la limpieza y unión de las bases de datos de las estaciones “Hubway Station”, de los viajes “Hubway trips”, y de datos climatológicos para 2011, 2012 y 2013. Después se llevó a cabo el análisis exploratorio de los datos que se consideraron relevantes para identificar los patrones de viajes de los pasajeros y se probaron dos modelos -LASSO, Random Forest y XGB- para la predicción de la duración de los viajes e identificación de los factores que tienen un impacto en ésta; posteriormente se modelaron los flujos para determinar la disponibilidad de las bicicletas en cada estación y se comparó el desempeño de ambos modelos.

Consideraremos nuestras predicciones como buenas a partir de que generen valor para la empresa. Esto es, la predicción debe ser útil al usuario para tomar sus decisiones de transporte casi en tiempo real, y también debe permitir al negocio monitorear de manera realista los flujos de bicicletas en Boston y las cicloestaciones.


## Comprensión de los Datos

En lo que resta de este documento analizamos los datos, y los preparamos para el modelado. Primero hacemos una exploración inicial de las bases y de valores faltantes. Asimismo, generamos variables útiles a partir de las ya existentes. Una vez hecho esto, mostramos nuestros principales hallazgos del análisis exploratorio de los datos. Por último, realizamos transformaciones finales e integramos una base final para pasar a los modelos.

Empezamos por cargar los datos.

```{r, include=FALSE}
trips <- read.csv("hubway_trips.csv", header = TRUE)
stations <- read.csv("hubway_stations.csv", header = TRUE)
weather <- read.csv("weather.csv", header = TRUE)
```

Buscamos NAs en las variables para poder tomar decisiones al respecto.

````{r}

# asignar NAs a valores vacíos de measurement_flag
weather$Measurement_Flag[weather$Measurement_Flag==" "] <- NA

# función para NAs
check_nas <- function(df){
  df %>%
    select_if(~sum(is.na(.)) > 0) %>%
    miss_var_summary()
}

# tabla resumen de missing values: trips
kable(check_nas(trips), booktabs=T, align = 'c',
      col.names = c("Variable", "Cantidad","%"), digits = 4, caption = "trips") %>%
  kable_styling(position = "center", latex_options="HOLD_position")

# tabla resumen de missing values: weather
kable(check_nas(weather), booktabs=T, align = 'c',
      col.names = c("Variable", "Cantidad","%"), digits = 4, caption = "weather") %>%
  kable_styling(position = "center", latex_options="HOLD_position")

````


#### Análisis para imputación de estaciones
```{r}
prcnt_sameStation <- trunc(sum(trips$strt_statn == trips$end_statn,
                               na.rm = T) / nrow(trips) * 100 * 100)/100
NA_either <- sum(is.na(trips$strt_statn) | is.na(trips$end_statn))
```

Se decide eliminar la variable "Quality_Flag", pues esta contiene únicamente NAs.

Además, analizando las observaciones con NA en "strt_statn" o "end_statn", notamos que estas sí tienen valores para variables importantes como "duration", y que no necesariamente coinciden en tener NA para ambas variables, por lo que sí podrían ser útiles si se les imputara algún valor. Lo más directo sería imputarle a la variable con NA el valor de la variable que sí tiene información. Sin embargo, notamos que tan solo el `prcnt_sameStation`% de las observaciones siguen este comportamiento. Dado que para poder predecir la disponibilidad de bicicletas por estación las variables de "strt_statn" o "end_statn" serán muy importantes, se decide simplemente eliminar las observaciones con NA en cualquiera de estas dos variables. Dado que son únicamente `NA_either` las observaciones que cumplen con esta última característica, el efecto eliminarlas es prácticamente nulo.

```{r}
weather$Quality_Flag <- NULL
#weather$Measurement_Flag <- NULL
trips <- trips[!is.na(trips$strt_statn) & !is.na(trips$end_statn), ]
```

Nótese que la información contenida en "birth_date" no es directamente útil, pues se tienen observaciones de distintos años. La información que seguramente será muy relevante es la edad del usuario cuando hizo uso del servicio, no su edad actual. Por ello, para poder analizar la variable "birth_date" y tomar una decisión respecto a sus NA, primero se procesa las variables "start_date", "end_date", y finalmente se genera una variable con la edad a partir de "birth_date". Asimismo, se procesan las fechas en la base del clima para extraer una fecha y hora utilizables. Todo esto con la finalidad de poder realizar un análisis exploratorio que posteriormente permita tomar una decisión.

```{r}
# Se divide start_date en fecha y hora para extraer la información
colnames(trips)[colnames(trips) == 'start_date'] <- 'start_DateTime'
startDateTime <- strsplit(trips$start_DateTime, ' ')

startDate <- sapply(startDateTime, "[", 1)
trips$start_date <- as.Date(startDate, '%m/%d/%Y') %>% date()
trips$start_year <- trips$start_date %>% year()
trips$start_month <- trips$start_date %>% month()
trips$start_weekday <- weekdays(trips$start_date)

startTime <- sapply(startDateTime, "[", 2)
trips$start_hour <- as.POSIXct(startTime,format="%H:%M:%S") %>%
  hour()
trips$start_minute <- format(as.POSIXct(startTime,format="%H:%M:%S"),"%M")


# Se divide end_date en fecha y hora para extraer la información (poder utilizarla posteriormente)
colnames(trips)[colnames(trips) == 'end_date'] <- 'end_DateTime'
endDateTime <- strsplit(trips$end_DateTime, ' ')

endDate <- sapply(endDateTime, "[", 1)
trips$end_date <- as.Date(endDate, '%m/%d/%Y')
trips$end_year <- format(trips$end_date, '%Y')
trips$end_month <- format(trips$end_date, '%m')
trips$end_weekday <- weekdays(trips$end_date)

endTime <- sapply(endDateTime, "[", 2)
trips$end_hour <- format(as.POSIXct(endTime,format="%H:%M:%S"),"%H")
trips$end_minute <- format(as.POSIXct(endTime,format="%H:%M:%S"),"%M")

# Se genera la edad del usuario al empezar con el servicio
trips$age <- as.integer(trips$start_year) - trips$birth_date

# se hace lo mismo para sacar fecha y hora en la base de clima
weather$start_date <- weather$DATE %>% strsplit(' ') %>%
  sapply("[", 1) %>% as.Date('%Y%m%d') %>% date()

weather$start_hour <- weather$DATE %>% strsplit(' ') %>%
  sapply("[", 2) %>% as.POSIXct(format="%H:%M") %>%
  hour()

# remover objetos grandes
rm(endDateTime,startDateTime,endDate,endTime,startDate,startTime)

```

#### Unión de base de clima con viajes


```{r, include=FALSE, echo=FALSE}
# Para analizar problemas con unir trips y weather
naive_merge <- merge(trips[, c('start_date', 'start_hour')],
                     weather[, c('start_date', 'start_hour', 'HPCP')],
                     by = c('start_date', 'start_hour'), all.x = T)
HPCP_NAs_prcnt <- trunc(mean(is.na(naive_merge$HPCP))*100*100)/100
rm(naive_merge)
```

Ahora, se procede a unir la base que contiene la información sobre los viajes con las columnas relevantes de las otras bases. Esto se hace primero con la información sobre el clima a la hora que inicia y termina el viaje. Naturalmente, sería ideal tener información sobre el nivel de precipitación registrada durante cada minuto de los viajes de los usuarios. Sin embargo, este no es el caso. En nuestra base principal tenemos `length(unique(trips$start_date))` días para los cuales se registró al menos un viaje, pero únicamente contamos con `length(unique(weather$start_date))` días que sí tienen mediciones. Más aún, si fuésemos a asignar valores a cada viaje para el nivel de precipitación con base en un match estricto con la fecha y hora de la medición, tendríamos que el `HPCP_NAs_prcnt`% de esta nueva columna serían NAs. Consideramos que esta variable podría tener mucha información importante como para eliminarla, y que las mediciones con las que contamos aún pueden decirnos mucho más: cuando llueve, las afectaciones de dicho fenómeno son persistentes temporalmente, pues el hecho de que no se tenga medición para una hora después de un registro, esto no implica que ya no esté lloviendo, o que el clima ha mejorado. Del mismo modo, las calles suelen continuar mojadas una o varias horas después. Por otra parte, cuando llueve, esto no sucede sin previo aviso, de un minuto a otro. Con base en este razonamiento, se decide utilizar las pocas observaciones que sí se tienen para crear un índice alrededor de la hora sobre la cual sí se tien registro de la siguiente manera: para cada día y hora en que se registró un viaje, si existe un registro para el clima este se deja intacto. Cuando no, se utiliza un promedio de la lluvia registrada en el intervalo que comprende desde tres horas antes (efectos persistentes del clima del pasado) y hasta una hora después (previsión del clima futuro dado el presente). Nótese que los registros del nivel de precipitación en esta nueva variable únicamente toman `length(unique(trips$HPCP))-1` valores posibles. Como los NA aún persisten, a estos se les asigna el valor "SR" (Sin Registro), y se trata a toda la variable como un factor por intervalos.

Usando un razonamiento similar, se considera que, en general, el hecho de que haya llovido durante el día puede también decirnos algo de información relativamente distinta. Por un lado, si había llovido antes de tomar una bicicleta, esto podría tener un efecto en las decisiones de los usuarios a través de sus ánimos y la expectativa del clima para el resto del día. Por otro, si aún no había llovido, es altamente probable que los usuarios hayan elegido iniciar un viaje con base en sus propias predicciones respecto al clima para el resto del día con base en factores que, para efectos de nuestros datos, no son observables. Es por ello que también se crea una variable que nos informa si llovió o no en un determinado día.


```{r}

# Imputación a los NA para HPCP en la base trips
weather$start_hour <- as.integer(weather$start_hour)
unique_dates <- unique(trips$start_date)
weather_calendar <- as.data.frame(matrix(NA, nrow = length(unique_dates), ncol = 25))
colnames(weather_calendar) <- c('start_date', 0:23)
weather_calendar$start_date <- unique_dates
for ( i in 1:nrow(weather_calendar) ) {
  curr_date <- weather_calendar$start_date[i]
  ss_by_date <- weather[weather$start_date == curr_date, c('start_hour', 'HPCP')]
  if (nrow(ss_by_date) > 0) {
    aux <- 3
    for ( j in 0:22 ) {
      ss_by_hr <- ss_by_date[ss_by_date$start_hour >= (j-3+aux) & ss_by_date$start_hour <= (j+1),
                             c('start_hour', 'HPCP')]
      est_weather <- sum(ss_by_hr$HPCP, na.rm=T) / 5
      if (nrow(ss_by_hr) > 0) {
        weather_calendar[i, j+2] <- est_weather
      }
      true_weather <- ss_by_date[ss_by_date$start_hour == j, c('start_hour', 'HPCP')]
      if (nrow(true_weather) > 0) {
        weather_calendar[i, j+2] <- max(true_weather$HPCP[1], est_weather)
      }
      aux <- max(aux - 1,0)
    }
    # La hora 23, inalcanzable en el loop anterior
    ss_by_hr <- ss_by_date[ss_by_date$start_hour >= (23-3) & ss_by_date$start_hour <= (23),
                           c('start_hour', 'HPCP')]
    est_weather <- sum(ss_by_hr$HPCP, na.rm=T) / 5
    if (nrow(ss_by_hr) > 0) {
        weather_calendar[i, 23+2] <- est_weather
    }
    true_weather <- ss_by_date[ss_by_date$start_hour == 23, c('start_hour', 'HPCP')]
    if (nrow(true_weather) > 0) {
      weather_calendar[i, 23+2] <- max(true_weather$HPCP[1], est_weather)
      }
  }
}

date_matcher <- melt(weather_calendar, id.var = 'start_date', variable.name = 'start_hour')
date_matcher$start_hour <- as.integer(date_matcher$start_hour)
colnames(date_matcher)[3] <- 'HPCP'
trips <- merge(trips, date_matcher, by=c("start_date", "start_hour"), all.x=T)


# Creación de la variable indicadora de día lluvioso
rained_matcher <- aggregate(HPCP~start_date, data=weather, FUN=sum, na.action = na.omit)
rained_matcher$rained <- ifelse(rained_matcher$HPCP>0, 1, 0)
trips <- merge(trips, rained_matcher[,c('start_date', 'rained')], by='start_date', all.x=T)

HPCP_NAs_prcnt <- trunc(mean(is.na(trips$HPCP))*100*100)/100 
# Porcentaje de NAs en HPCP

rained_NAs_prcnt <- trunc(mean(is.na(trips$rained))*100*100)/100 
# Porcentaje de NAs en rained

# Se forman intervalos para el nivel de lluvia
trips$HPCP <- cut(trips$HPCP,
                  breaks=c(-0.001, seq(0,0.09,.015), seq(0.1,0.25,0.025),0.35,0.5,0.7,1.5),
                  labels=c(0, seq(0,0.09,.015)[-1], seq(0.1,0.25,0.025),0.35,0.5,0.7,1.5))


# Se asigna SR a las NA para poder trabajar como factor
trips[is.na(trips$rained), 'rained'] <- 'SR'
trips$HPCP = factor(trips$HPCP, levels=c(levels(trips$HPCP), 'SR'))
trips$HPCP[is.na(trips$HPCP)] = 'SR'


# Transformamos a numéricas la variable de lluvia
#HPCP 2
trips$hpcp2 <- 0
trips$hpcp2[trips$HPCP=="SR"] <- 1
summary(trips$hpcp2)

# HPCP numerica
trips$HPCP[trips$HPCP=="SR"] <- 0
trips$HPCP <- trips$HPCP %>% as.character %>% as.numeric

# Se transforman a factor
trips$rained <- trips$rained %>% as.factor
```

Con lo anterior, se disminuyó el número de NAs en "HPCP" a `HPCP_NAs_prcnt`, y además tenemos información meteorológica útil para el `1-rained_NAs_prcnt` de las observaciones, que dado el tamaño de la base, es una buena cantidad.

También se asigna `Measurement_Flag`.

```{r}
trips <- merge(trips, weather[,c('start_date','start_hour', 'Measurement_Flag')],
               by = c('start_date','start_hour'), all.x = T)

trips$Measurement_Flag[is.na(trips$Measurement_Flag)] <- "unknown"

```

Para concluir el análisis inicial, transformamos las variables.

```{r}
# categóricas
trips$subsc_type <- trips$subsc_type %>% as.factor
trips$gender <- trips$gender %>% as.factor
trips$status <- trips$status %>% as.factor
trips$bike_nr <- trips$bike_nr %>% as.factor
trips$zip_code <- trips$zip_code %>% as.factor
trips$Measurement_Flag <- trips$Measurement_Flag %>% as.factor

trips$start_year <- trips$start_year %>% as.factor
trips$end_year <- trips$end_year %>% as.factor
trips$start_month <- trips$start_month %>% as.factor
trips$end_month <- trips$end_month %>% as.factor
trips$start_weekday <- trips$start_weekday %>% as.factor
trips$end_weekday <- trips$end_weekday %>% as.factor

trips$strt_statn <- trips$strt_statn %>% as.factor
trips$end_statn <- trips$end_statn %>% as.factor

# numéricas
trips$start_hour <- trips$start_hour %>% as.integer
trips$end_hour <- trips$end_hour %>% as.integer
trips$start_minute <- trips$start_minute %>% as.integer
trips$end_minute <- trips$end_minute %>% as.integer

summary(trips)

```

## EDA


### Exploración georreferenciada

Antes de realizar un análisis estadístico, para poder desarrollar una mejor intuición visual sobre las rutas más frecuentes hemos creado un dashboard donde se grafican georrefernciadamente 1000 viajes aleatorios de la base de datos. En el dashboard se dimensiona la importancia de cada estación. Además, se puede explorar con grado de detalle cada estación y obtener información sobre sus rutas más frecuentes y menos frecuentes.

![Mapa del centro de Boston.](mapa.png)

![Leyenda para el dashboard.](id.png){width=50%}

Bievenido a nuestra herramienta interactiva de visualización de viajes en bicicleta en Boston. Aquí puede explorar los viajes más frecuentes y conocer más acerca de las dinámicas de movilidadn de la ciudad.

Lo primero que notamos es que la gran mayoría de los viajes son rosas, es decir dentro de la municipalidad de Bostón, relativamente pocos viajes ocurren fuera. Asimismo, el epicentro de la movilidad son las estaciones cercanas a la pequeña peninsula de Boston. Asimismo, el segundo componente de estaciones más conectado es Cambridge y el tercero es Somerville.

En la herramienta siguiente se puede explorar los viajes más frecuentes estación por estación. En la siguiente visualización se muestran solamente 1,000 viajes aleatorios de toda la muestra de datos,

[en esta visualización](https://marcoyel21.github.io/gephi_vis/network/)



### Análisis estadístico

Una vez construidas las variables temporales, procedemos a hacer el análisis exploratorio de los datos, teniendo en mente que la variable objetivo es la duración de los viajes.


#### Análisis univariado

Primero, revisamos la distribución de las variables. Graficamos histogramas para las variables continuas y gráficas de barras para las categóricas.


```{r}
# histograma para variables continuas
myhist <- function(yvar){
  ggplot(trips, aes_(x=as.name(yvar), fill=as.name(yvar)))+
    geom_histogram()+
    ggtitle(paste0(as.name(yvar)))+
    xlab("")+
    ylab("")+ geom_rangeframe()+
    theme_bw()+
    theme(axis.line = element_line(colour = "black"),
          axis.text.y = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          legend.position = 'none')
}

hists<- trips %>%
  select(
    duration,
    start_hour,
    age
  ) %>%
  names() %>%
  lapply(myhist)

# grafico las variables
grid.arrange(grobs=hists,ncol=3,
             top=textGrob("Distribución de las variables"))
```

En esta gráfica es claro que hay presencia de outliers en la variable de duración. Esto podría deberse a errores en el registro, y podría afectar nuestras predicciones. Más adelante se toma una decisión al respecto.


```{r}
# barras para las categóricas
# histograma para variables continuas
mybar <- function(yvar){
  ggplot(trips, aes_(x=as.name(yvar), fill=as.name(yvar)))+
    geom_bar()+
    ggtitle(paste0(as.name(yvar)))+
    xlab("")+
    ylab("")+ geom_rangeframe()+
    theme_bw()+
    theme(axis.line = element_line(colour = "black"),
          axis.text.y = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          legend.position = 'none')
}

bars <- trips %>%
  select(
    start_year,
    start_month,
    strt_statn,
    end_statn,
    start_weekday,
    subsc_type,
    gender,
    rained,
    HPCP,
    hpcp2,
    Measurement_Flag
  ) %>%
  names() %>%
  lapply(mybar)

# grafico las variables
grid.arrange(grobs=bars,ncol=4,
             top=textGrob("Distribución de las variables"))
```

Aquí podemos notar que los viajes están uniformemente distribuidos a lo largo de los días de la semana, aunque dominan los viajes del 2013 y del mes de agosto, sin haber observaciones en los meses de invierno. Por otra parte, la varianza entre uso de estaciones es notable.


## Análisis bivariado

```{r, echo=FALSE, eval=FALSE, include=FALSE}
# Mapa de calor start y end station
x <- trips %>% count(strt_statn, end_statn)
summary(x)

y <- pivot_wider(x, id_cols=c("strt_statn"),
                 names_from=c("end_statn"),
                 values_from=c("n"),
                 values_fill=0)
class(y)

# Matrix format. nota. las columnas son end stations y las filas start stations
rownames(y) <- y[,1] %>% unlist()
y <- y %>% dplyr::select(c(-1))
y <- as.matrix(y)


heatmaply(y,
          dendrogram = "none",
          colors = c("wheat","navyblue"),
          grid_color = "white",
          fontsize_row = 7, fontsize_col = 7,
          xlab = "",
          ylab = "",
)
```

Ahora procedemos a explorar relaciones entre los usuarios y la duración, en particular la edad y el género.

```{r}
# Se muestra la relación entre edad y duración (acotada superiormente por su percentil 99%)
ggplot(trips, aes(age, duration)) +
  geom_point(alpha=0.3) +
  geom_smooth() +
  ylim(0, quantile(trips$duration, probs=0.99))

corr_age_duration <- cor(trips$age, trips$duration, use = "complete.obs")
```

A pesar de una gran variación tanto en duración como edad, la correlación entre éstas es prácticamente nula.

```{r, eval=FALSE, echo=FALSE}
# Histograma de la edad para todas las observaciones
ggplot(data=subset(trips, !is.na(age)), aes(x=age)) +
  geom_histogram() +
  geom_vline(aes(xintercept=mean(age, na.rm=T)), color="black", size=1) +
  geom_vline(aes(xintercept=median(age, na.rm=T)), color="black", linetype="dashed", size=1)

```

Podemos notar que predominan los usuarios hombres, sobre todo a partir de los 30, donde la frecuencia de uso de las mujeres cae abruptamente. En general, puede verse que el grueso de los usuarios son jóvenes.

```{r}
# Histograma de la edad por género
ggplot(data=subset(trips, !is.na(age)), aes(x=age, color=gender, fill=gender)) +
  geom_histogram(alpha=0.2, position="identity") +
  geom_vline(aes(xintercept=mean(age, na.rm=T)), color="orange", size=1) +
  geom_vline(aes(xintercept=median(age, na.rm=T)), color="black", linetype="dashed", size=1) +
  annotate("text",                        # Add text for mean
           x = 25,
           y = 30000,
           label = paste("Median =", median(trips$age, na.rm=T)),
           col = "black",
           size = 4) +
  annotate("text",                        # Add text for mean
           x = 42,
           y = 30000,
           label = paste("Mean =", trunc(mean(trips$age, na.rm=T)*100)/100),
           col = "orange",
           size = 4)
```

Dada la distribución que sigue la edad, observada en los histogramas, se imputa la mediana a las edades.

```{r}
trips[is.na(trips$age), 'age'] <- median(trips$age, na.rm = T)
```

Pasando ahora la atención a las variables de "gender" y de "zip_code", es posible notar que valores vacíos de "gender" corresponden en su totalidad a los usuarios no registrados, y sólo unos pocos adicionales (155) son usuarios registradas pero sin reportar su "zip_code". A estos se les imputa "Unknown" y se les trata como factor.

```{r}
empty_gender <- sum(trips$gender=='')
empty_zipcode <- sum(trips$zip_code=='')
unregistered <- sum(trips$subsc_type!='Registered')
aux <- t(cbind(unregistered, empty_gender, empty_zipcode))
aux <- cbind(c('subsc_type','gender','zip_code'), aux, aux)
aux[,3] <- trunc(as.numeric(aux[,2])/nrow(trips)*1000000)/1000000*100
rownames(aux) <- NULL
kable(aux, col.names = c("Variable","Número de valores vacíos", "%"), align = "lrr", booktabs=T) %>%
  kable_styling(position = "center", latex_options="HOLD_position")

# Asigna un valor a los valores vacíos del género y zip_code.
trips$gender <- factor(trips$gender, levels=c(levels(trips$gender), 'Unknown'))
trips$gender[is.na(trips$gender)] <- 'Unknown'
trips$gender <- droplevels(trips$gender)

trips$zip_code <- factor(trips$zip_code, levels=c(levels(trips$zip_code), 'Unknown'))
trips$zip_code[is.na(trips$zip_code)] <- 'Unknown'

```

## Preparación de los Datos

Eliminamos también `sum(trips$duration < 0)` observaciones que registran una duración negativa, pues es evidente que hubo un error en el registro que vuelve las observaciones inútiles. Al ser un número tan pequeño, esta acción no nos genera preocupación. Asimismo, existen `sum(trips$duration == 0)` observaciones con una duración de cero, y se decide también eliminarlas, pues podrían representar movimientos accidentales o reacomodos ocasionados por los usuarios y no una salida de una bicicleta. Cabe destacar que sí existen diez observaciones que tienen una duración de cero, pero que registran distintas estaciones en el comienzo y final del viaje. Al ser un número tan pequeño, eliminarlas es nuevamente prácticamente insignificante.

```{r}
trips <- trips[trips$duration>0, ]
```

Ahora buscamos columnas con el mismo valor para todas las observaciones, pues de ser el caso no serían útiles para el modelo.

```{r}

# trips
uselessCols_trips <- c()
for (i in colnames(trips)) {
  if ( length(unique(trips[[i]]))==1 ) {
    uselessCols_trips <- c(uselessCols_trips, i)
  }
}

# stations
uselessCols_stations <- c()
for (i in colnames(stations)) {
  if ( length(unique(stations[[i]]))==1 ) {
    uselessCols_stations <- c(uselessCols_stations, i)
  }
}

# weather
uselessCols_weather <- c()
for (i in colnames(weather)) {
  if ( length(unique(weather[[i]]))==1 ) {
    uselessCols_weather <- c(uselessCols_weather, i)
  }
}

```

Notamos que la variables "status" en la base con información de los viajes contiene un único valor presente en todas las observaciones. Lo mismo sucede con "STATION", "STATION_NAME", "ELEVATION", "LATITUDE" y "LONGITUDE" en la base con datos del clima. Se presentan los valores de las variables mencionadas para evaluar su utilidad.

```{r}

uselessCols <- c(uselessCols_trips, uselessCols_weather)
uValues <- c(unique(trips[,uselessCols_trips]), unique(weather[,uselessCols_weather]))
names(uValues) <- NULL
kable(cbind(uselessCols, uValues),
      col.names = c("Nombre de la variable","Valor único"), align = "lr", booktabs=T) %>%
  kable_styling(position = "center", latex_options="HOLD_position")

```

Se elimina, entonces, la variable "status", pues esta no contiene información útil.
```{r}
trips$status <- NULL

n_obs <- c()
for (i in unique(stations$municipal)) {
  n_obs <- c(n_obs, nrow(stations[stations$municipal==i,]))
}

kable(cbind(unique(stations$municipal), n_obs),
      col.names = c("Municipalidad","Número de estaciones"), align = "lr", booktabs=T) %>%
  kable_styling(position = "center", latex_options="HOLD_position")

```

Se presentan finalmente  algunos estadísticos relevantes sobre las variables numéricas de los viajes.

```{r}
# No muestro las variables de id de la estación y viaje, ni el año de nacimiento 
tdf <- select_if(trips, is.numeric)
tdf <- subset(tdf, select = -c(seq_id,hubway_id))
aux <- matrix(NA, ncol = 8, nrow = 9) # Si no corre, cambiar 7 por 9
k <- 1
for (i in colnames(tdf)) {
  qu <- quantile(trips[[i]], probs = c(0.05, 0.25, 0.5, 0.75, 0.95), na.rm = TRUE)
  n <- length(which(!is.na(trips[[i]])))
  NAs <- nrow(trips)-n
  mean <- format(round(mean(trips[[i]], na.rm = TRUE), digits = 4), scientific = FALSE)
  min <- min(trips[[i]],na.rm = TRUE)
  max <- max(trips[[i]], na.rm = TRUE)
  aux[k,] <- c(mean, min, qu, max)
  k <- k + 1
}
colnames(aux) <- c("Media", "Mín.", "p05", "p25", "p50", "p75", "p95", "Máx.")
rownames(aux) <- colnames(tdf)
kable(aux, booktabs=T) %>% kable_styling(position = "center", latex_options="HOLD_position")

rm(tdf, hists, ss_by_date, ss_by_hr)
```

Se asignan las coordenadas de cada estación por cada arrivo y salida. Asimismo, se utilizan para calcular las distancias entre ellas.

```{r}
# Coordenadas
stations$strt_statn <- stations$id
stations$end_statn <- stations$id
trips <- merge(trips, stations[, c('strt_statn', 'lat','lng')], by='strt_statn', all.x=T)
colnames(trips)[colnames(trips) == 'lat'] <- 'start_lat'
colnames(trips)[colnames(trips) == 'lng'] <- 'start_lng'
trips <- merge(trips, stations[, c('end_statn', 'lat','lng')], by='end_statn', all.x=T)
colnames(trips)[colnames(trips) == 'lat'] <- 'end_lat'
colnames(trips)[colnames(trips) == 'lng'] <- 'end_lng'

# Distancias en metros
trips$distance <- distGeo(as.matrix(cbind(trips$start_lng,
                                          trips$start_lat)),
                          as.matrix(cbind(trips$end_lng, trips$end_lat)))
```

Por último, en lugar de usar el ID de la bici como una variable categórica, lo cual sería computacionalmente muy pesado ya que hay más de 1100 bicis, decidimos tomar la letra del ID como la familia de la bicicleta, o su generación, y el número de serie como proxy de la antigüedad de la bici, donde números más pequeños son bicicletas más viejas.

```{r}
# nuevas variables para bike nr

# numero de bicis en los datos
unique(trips$bike_nr) %>% length

# familia de la bici
trips$bike_fam <- substr((trips$bike_nr) %>% as.character(),1,1) %>%
  as.factor

# antigüedad
trips$bike_antiq <- substr(trips$bike_nr %>% as.character(),2,6) %>% as.numeric()

summary(trips$bike_antiq)

# sustituyo la mediana para la antigüedad de las bicis sin bike nr
trips$bike_antiq[is.na(trips$bike_antiq)] <- median(
  trips$bike_antiq, na.rm=T)

```


# Base final

Una vez hecho el análisis de los datos, guardamos la base final que usaremos para los modelos de ML.

```{r}
#primero seleccionamos las variables
trips_filter <- trips %>%
  select(-c("hubway_id","start_DateTime","end_DateTime",
            "birth_date","end_date","end_year",
            "end_month","end_weekday",
            "bike_nr",
            "end_hour","end_minute",
            "start_lat","start_lng","end_lat","end_lng"))


summary(trips_filter)

# guardo bases
save(trips_filter,file="base_modelo.RData")
# tambien guardamos la base completa
save(trips, file="base_trips.RData")
```





