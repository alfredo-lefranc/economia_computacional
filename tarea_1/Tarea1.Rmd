---
title: 'Economía Computacional: Tarea 1'
author: "Alfredo Lefranc, Marco Ramos, Rafael Sandoval y Cynthia Valdivia"
date: '2021'
output: pdf_document
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
```

```{r liberias , message=FALSE}
library(tidyverse)
library(data.table)
library(RCT)
library(knitr)
library(lfe)
library(broom)
library(stargazer)
library(kableExtra)
library(naniar)
library(nnet)
```

En esta tarea pondrán en práctica los conceptos de High Dimensional Inference y Regresión. La base de datos muestra las compras de helados Ben & Jerry. Cada fila es una compra. Cada columna es una característica del helado comprado o de la persona que compró. 


## Limpieza de datos

Carga los datos en BenAndJerry.csv. 

```{r }
# Carga la base de datos
base<-read.csv("BenAndJerry.csv")
```


### 1. Cuales son las columnas de la base? Muestra una tabla con ellas
```{r }
columnas <- (as.data.frame(colnames(base)))

kable(columnas, booktabs=T, align = 'c', col.names = c("Columnas"))
```

### 2. A qué nivel está la base? Esto es, cuál es la variable que define la base de manera única. Si no la hay, crea una y muestra que es única a nivel de la base (Muestra el código)

Así como está la base sin niguna modificación, el nivel es la compra. Es decir, cada fila representa una transacción realizada por un hogar. Esto lo podríamos modificar para que la unidad sea el hogar o cualquier otra variable.

No hay una variable explícita que identifique cada observación de manera única pero sí hay una manera implícita y es el índice de cada fila. De tal forma, podemos usar el identificador de y concatenarlo con una nueva variable para identificar la transacción por hogar para crear un identificador único a nivel de la base.


```{r}
base2 <- base %>% group_by(household_id) %>% 
          mutate(idper = sequence(n()))
base$idper <- base2$idper

base$id <- base$idper + base$household_id*100

```


### 3. Que variables tienen valores vacíos? Haz una tabla con el porcentaje de vacíos para las columnas que tengan al menos una observación vacía

Los NAs de las variables numéricas son identificables mediante un summary.
````{r, eval=FALSE}
summary(base)

```

Las variables *promotion_type, scantrack_market_identifier, female_head_occupation* y *tv_items* tienen valores faltantes. Sin embargo, es posible que las variables de caracteres también tengan valores vacíos.

```{r, include=FALSE}
# subset de las variables de texto
charvar <- select(base,c(6:8,32,33))

# revisamos que no tengan valores vacíos
table(charvar$size1_descr=="")
table(charvar$flavor_descr=="")
table(charvar$formula_descr=="")
table(charvar$female_head_birth=="")
table(charvar$male_head_birth=="")

base$female_head_birth[base$female_head_birth==""]<- NA
base$male_head_birth[base$male_head_birth==""]<-NA
```

Al revisar estas variables, notamos que *male_head_birth* y *female_head_birth* también tienen valores vacíos. En general encontramos lo siguiente:

```{r}
kable( (base %>% select_if(~sum(is.na(.)) > 0) %>% 
          miss_var_summary()), booktabs=T, align = 'c',
       col.names = c("Variable","Cantidad","%"))
```


### 4. Haz algo con los valores vacíos (Se deben reemplazar por algún valor? Eliminar de la base?). Justifica tu respuesta. 

Pues dependiendo de la cantidad de valores vacíos, de si hay un patrón en los valores vacíos y las características de cada variable podemos proponer una estrategia, por ejemplo imputación o quitar esas observaciones. En este sentido tenemos que realizar un análisis por variable:

**promotion_type**
````{r}
summary(factor(base$promotion_type))
```
En esta variable podría ser que los NAs nos indiquen que sencillamente no hubo ninguna promoción (y eso podría explicar que casi el 60% de sus valores sean NAs). En este caso podemos suponer eso e imputarle un valor de 0 a cada `NA`.

````{r}
base$promotion_type[is.na(base$promotion_type)] <- 0
```

**scantrack_market_identifier**

````{r}
summary(factor(base$scantrack_market_identifier))

```

````{r}
susp<-base%>% select(fips_state_code,fips_county_code,type_of_residence,scantrack_market_identifier)

```


En este caso es más complejo porque es muy probable que cada valor corresponda a un producto, a una clasificación de cliente o a cualquier otra cosa. En este caso, lo que podríamos hacer es ver si podemos inferir está información de otras varaibles, de lo contrario imputar sería una muy mala idea pues estaríamos creando ruido en nuestra información. Investigando un poco nos dimos cuenta que se trata de una clasificación del posicionamiento en el mercado.

**female_head_occupation y female_head_birth**

```{r}
aux<-base %>% select(age_of_female_head,
                     female_head_occupation,
                     female_head_education,
                     female_head_employment,
                     female_head_birth) %>%
  filter (is.na(female_head_occupation))

summary((aux))
summary(aux$age_of_female_head[aux$female_head_birth==""])
```

Explorando los datos, notamos que todos los NAs de las variables *female_head_occupation* y *female_head_birth* coinciden, y además corresponden a observaciones en que se registra una edad, educación y ocupación de la jefa del hogar de cero. Esto nos lleva a concluir que en los hogares que hicieron esas compras no hay una jefa de hogar femenina. En este sentido creamos una nueva categoría de ocupación de mujeres con estás características con el número 0, la cual imputamos a los valores faltantes. Por su parte, dejamos como NAs los valores faltantes de la variable *female_head_birth*.


````{r}
base$female_head_occupation[is.na(base$female_head_occupation)] <- 0
```


**male_head_birth**

```{r}
aux2<-base %>% select(age_of_male_head,
                      male_head_occupation,
                      male_head_education,
                      male_head_employment,
                      male_head_birth) %>%
  filter (is.na(male_head_birth))

summary((aux2))
```
Los valores faltantes de *male_head_birth* coinciden con ceros en edad, educación y empleo del jefe del hogar masculino, aunque curiosamente sí se tiene registro de su ocupación. Concluimos, como en el caso de las mujeres, que se trata de casos, en los que la compra corresponde a hogares sin un jefe del hogar masculino, y decidimos ignorar estos valores vacíos.


**tv_items**

En este caso, puede que la variable indique una cantidad de *items* o bien que indique una categoría. En el caso primero, parecería que no contemplaron una cantidad de ceros o de más de 3, bien podríamos imputar el valor de 0. En el segundo caso, no tenemos manera de saber el tipo de categorías son, en ese caso no podríamos imputar tan facilmente: podríamos agregar un valor para identificarlas (como un 0) o bien simplemente prescindir de dichas observaciones (lo cuál no afectaría nuestro análisis debido a que son tan solo 34 observaciones). Optamos por imputarles el valor de cero, dado que esa opción es congruente sea la variable categórica o numérica.


````{r}
base$tv_items[is.na(base$tv_items)] <- 0
summary(factor(base$tv_items))
```

### 5. Muestra una tabla de estadisticas descriptivas de la base. Esta debe tener cada columna númerica con algunas estadísticas descriptivas (N, media, min, p05, p25, p50, p75, p90, p95, max). 

Sin hacer ninguna adecuación en el tipo de variables, la tabla es la siguiente:

````{r}
b <- read.csv("BenAndJerry.csv")
b<- summary_statistics(b,probs=c(0,0.05,0.25,0.5,0.75,0.9,0.95,1),na.rm=T)
b<- b %>% mutate_at(vars(-variable),funs(round(.,2))) %>%
  rename(mín=4) %>%
  rename(máx=11)

options(scipen=999) # quitamos notación científica
kable(b,booktabs=T, align = 'c')
```

No obstante, algunas de estas variables en realidad no son numéricas, por lo que sus estadísticas descriptivas podrían ser engañosas.

### 6. Hay alguna númerica que en verdad represente una categorica? Cuales? Cambialas a factor

```{r, include=FALSE}
numericas<-base%>% select(where(is.numeric))
summary(numericas)
```

De las variables numéricas, por su nombre y rango de valores, podemos inferir que las siguientes son categóricas:
*promotion_type, household_income, age_of_female_head, age_of_male_head, male_head_employment, female_head_employment, marital_status, male_head_occupation, female_head_occupation, household_composition, race, hispanic_origin, region, scantrack_market_identifier, fips_state_code, fips_county_code, type_of_residence* y *household_internet_connection*.


Sin embargo, las siguientes podrían ser o no ser categóricas: *tv_items, kitchen_appliances, age_and_presence_of_children, male_head_education, female_head_education.*
````{r}
variables_seguras<-c("promotion_type",
                     "household_income",
                     "age_of_female_head",
                     "age_of_male_head",
                     "male_head_employment",
                     "female_head_employment",
                     "marital_status",
                     "male_head_occupation",
                     "female_head_occupation",
                     "household_composition",
                     "race",
                     "hispanic_origin",
                     "region",
                     "scantrack_market_identifier",
                     "fips_state_code",
                     "fips_county_code",
                     "type_of_residence",
                     "household_internet_connection")

variables_no_seguras<-c("tv_items",
                        "kitchen_appliances",
                        "age_and_presence_of_children",
                        "male_head_education",
                        "female_head_education")

base[,variables_seguras] <- lapply(base[,variables_seguras] , factor)
base[,variables_no_seguras] <- lapply(base[,variables_no_seguras] , factor)

summary(base[,variables_no_seguras])

```

Parece que *tv_items, kitchen_appliances, age_and_presence_of_children* no son categóricas después de todo. Las regresamos a numéricas otra vez, Por el contrario *male_head_education* y *female_head_education* parece que sí son categóricas.

````{r}
variables_numericas<-c("tv_items","kitchen_appliances","age_and_presence_of_children")
base[,variables_numericas] <- lapply(base[,variables_numericas] , as.numeric)
```


### 7. Revisa la distribución de algunas variables. Todas tienen sentido? Por ejemplo, las edades? 

````{r, warning=FALSE, message=FALSE}

myhist <- function(yvar){
  ggplot(numericas, aes_(x=as.name(yvar)))+
    geom_histogram()+
    ggtitle(paste0(as.name(yvar)))+
    xlab("")+
    ylab("")+
    theme(axis.text.y = element_blank())
}
hists<- numericas %>% select(price_paid_deal,
                             price_paid_non_deal,
                             coupon_value,
                             household_size:household_composition,
                             scantrack_market_identifier,
                             kitchen_appliances,
                             tv_items) %>%
        names() %>%
        lapply(myhist)

library(gridExtra)

grid.arrange(grobs=hists[1:10],ncol=4)
grid.arrange(grobs=hists[11:19],ncol=4)

```

No. Las edades de los jefes del hogar y el ingreso del hogar tienen valores muy bajos, lo que nos hace pensar que estas variables son categóricas (transformadas en el inciso anterior).


### 8. Finalmente, crea una variable que sea el precio total pagado y el precio unitario
````{r}
# precio total pagado
base <- base %>% mutate(total_price=price_paid_deal+price_paid_non_deal)
# precio unitario
base <- base %>% mutate(unit_price= (total_price)/quantity)
```


## Exploración de los datos 

Intentaremos comprender la elasticidad precio de los helados. Para ello, debemos entender: 

- La forma funcional base de la demanda (i.e. como se parecen relacionarse $q$ y $p$). 

- Qué variables irían en el modelo de demanda y cuáles no para encontrar la elasticidad de manera 'insesgada'. 

- Qué variables cambian la relacion de $q$ y $p$. Esto es, que variables alteran la elasticidad.

Algo importante es que siempre debemos mirar primero las variables más relevantes de cerca y su relación en: 

- Relación univariada

- Relaciones bivariadas

- Relaciones trivariadas

Importante: Las gráficas deben estar bien documentadas (título, ejes con etiquetas apropiadas, etc). Cualquier gráfica que no cumpla con estos requisitos les quitaré algunos puntos.

### 9. Cómo se ve la distribución del precio unitario y de la cantidad demandada. Haz un histograma.
````{r}
median_price <- quantile(base$unit_price)[3]

ggplot(base)+
  geom_histogram(aes(x=unit_price),alpha=0.9,col = 'black')+
  geom_vline(xintercept = median_price,size=0.5,colour="red", linetype = "dashed")+
  geom_text(aes(x=median_price+2.8, label=paste("Mediana =",median_price), y=4800),size=4, colour="red", vjust = -1, hjust = 1.2)+
  theme_bw()+
  labs(title="Histograma de precio unitario",x="Precio unitario",y="Frecuencia")

  
ggplot(base)+
  geom_histogram(aes(x=quantity),binwidth=1,alpha=0.9,col = 'black')+
  theme_bw()+
  labs(title="Histograma de cantidad",x="Cantidad",y="Frecuencia")

```

### 10. Grafica la $q(p)$. Que tipo de relación parecen tener? 

Aunque parece haber una relación negativa, marcada por las compras de 1 a 4 productos, esta no es tan clara para mayores cantidades.

````{r}
ggplot(base)+
  geom_point(aes(y=quantity, x=unit_price))+ 
  geom_smooth(formula=y~x,method=lm, color='2',aes(y=quantity, x=unit_price))+
  theme_bw()+
  labs(title="Demanda de helados en función del precio",
       x="Precio unitario",y="Cantidad demandada")
```

### 11. Grafica la misma relación pero ahora entre $log(p+1)$ y $log(q+1)$

Cuando hacemos la transformación, la relación negativa es más evidente:

````{r}
ggplot(base)+
  geom_point(aes(y=log(quantity+1),x=log(unit_price+1)))+ 
  geom_smooth(formula=y~x,method=lm, color='1',aes(y = log(quantity+1), x = log(unit_price+1)))+
  theme_bw()+
  labs(title = "Elasticidad precio de la demanda de helados",
       x="Precio unitario (log)", y="Cantidad demandada (log)")

```

### 12. Grafica la curva de demanda por tamaño del helado. Parece haber diferencias en la elasticidad precio dependiendo de la presentación del helado? (2 pts)

````{r}

ggplot(data = base, aes(y=log(quantity+1), x=log(unit_price+1),col=as.factor(size1_descr))) +
  geom_point(size=1, alpha=0.5) +
  geom_smooth(method='lm',
              formula= y~(x),
              se=FALSE, size=1)+
  theme_bw()+
  labs(title="Elasticidad precio demanda de helado por tamaño",
      y="Cantidad demandada (log)",
      x="Precio unitario (log)",
      col="Tamaño")

````
```{r}
# Prueba de hipotesis
elast16 <- lm(log(quantity+1)~log(unit_price+1), 
              data=base[base$size1_descr=="16.0 MLOZ",])
elast32 <- lm(log(quantity+1)~log(unit_price+1), 
              data=base[base$size1_descr=="32.0 MLOZ",])
a <- elast16$coefficients[2]-elast32$coefficients[2]
b <- (vcov(elast16)[2,2] + vcov(elast32)[2,2]) %>% sqrt()

# Estadístico t
a/b

```
Al realizar una prueba de hipótesis si los coeficientes obtenidos son iguales, se obtiene un estadístico t de -3, por lo que la prueba se rechazaría en favor de la diferencia de éstos.


### 13. Grafica la curva de demanda por sabor. Crea una variable con los 3 sabores más populares y agruga el resto de los sabores como 'otros'. Parece haber diferencias en la elasticidad precio dependiendo del sabor?
````{r}
summary(factor(base$flavor_descr))
```

Parece que los 3 sabores más populares son *CHERRY GRCA*, *CHC FUDGE BROWNIE* y *CHC CHIP C-DH*.

````{r}
base<-base%>% 
  mutate(sabores_pop= ifelse(flavor_descr=='CHERRY GRCA','cherry grca',
(ifelse(flavor_descr=='CHC FUDGE BROWNIE','chc fudge brownie',
(ifelse(flavor_descr=='CHC CHIP C-DH','chc chip c-dh','otros'))))))


ggplot(data = base, aes(y=log(quantity+1), 
                        x=log(unit_price+1),
                        col=as.factor(sabores_pop))) +
  geom_point(size=1, alpha=0.3) +
  geom_smooth(method='lm',
              formula= y~(x),
              se=FALSE, size=1)+
  theme_bw()+
  labs(title="Elasticidad precio demanda de helado por sabor",
      y="Cantidad demandada (log)",
      x="Precio unitario (log)",
      col="Sabor")

```
A diferencia de las muestras por tamaño del helado, las diferencias en la elasticidad precio demanda observadas para los sabores de helado aparentan ser muy pequeñas.

```{r}

echip <- lm(log(quantity+1)~log(unit_price+1), 
            data=base[base$sabores_pop=="chc chip c-dh",])
echerry <- lm(log(quantity+1)~log(unit_price+1), 
              data=base[base$sabores_pop=="cherry grca",])
efudge <- lm(log(quantity+1)~log(unit_price+1), 
             data=base[base$sabores_pop=="chc fudge brownie",])
eother <- lm(log(quantity+1)~log(unit_price+1), 
             data=base[base$sabores_pop=="otros",])

chipcherry <- (echip$coefficients[2]-echerry$coefficients[2])/
               ((vcov(echip)[2,2] + vcov(echerry)[2,2]) %>% sqrt())
chipfudge <- (echip$coefficients[2]-efudge$coefficients[2])/
               ((vcov(echip)[2,2] + vcov(efudge)[2,2]) %>% sqrt())
chipother <- (echip$coefficients[2]-eother$coefficients[2])/
               ((vcov(echip)[2,2] + vcov(eother)[2,2]) %>% sqrt())
cherryfudge <- (echerry$coefficients[2]-efudge$coefficients[2])/
               ((vcov(echerry)[2,2] + vcov(efudge)[2,2]) %>% sqrt())
cherryother <- (echerry$coefficients[2]-eother$coefficients[2])/
               ((vcov(echerry)[2,2] + vcov(eother)[2,2]) %>% sqrt())
fudgeother <- (efudge$coefficients[2]-eother$coefficients[2])/
               ((vcov(efudge)[2,2] + vcov(eother)[2,2]) %>% sqrt())


# Estadísticos t
tstats <- list(chipcherry = chipcherry,
               chipfudge = chipfudge,
               chipother = chipother,
               cherryfudge = cherryfudge,
               cherryother = cherryother,
               fudgeother = fudgeother)
tstats
```
Al evaluar la hipótesis nula de si los coeficientes estimados de la elasticidad precio demanda entre las submuestras contempladas eran iguales a un nivel de significancia de 5%, se rechazan las de `chc chip c-dh` con `cherry grca` y la de `cherry grca` con `otros`. 


## Estimación

### 14. Estima la regresión de la curva de demanda de los helados. Reporta la tabla de la regresión
````{r, results= 'asis'}
model_a<-lm(unit_price~quantity,data = base)
stargazer(model_a, type = "latex", title="Regresión", digits=1)

# quitamos columnas irrelevantes
base<- select (base,-c(sabores_pop))

# convertimos sabores en dummies y ponemos como base los de vainilla
base$flavor_descr <- relevel(factor(base$flavor_descr),"VAN")
#base$size1_descr <- factor(base$size1_descr,levels=1:2, labels=c("small","big")) 

# uso de cupon / no uso de cupon
base$coupon <- factor(base$coupon_value>0)

# región
levels(base$region) <- c("East","Central","South","West")

# estado civil
base$married <- factor(base$marital_status==1)

# raza
base$race <- factor(base$race, levels= 1:4)
levels(base$race) <- c("White","Black","Asian","Other")

# hispano
base$hispanic_origin <- factor(base$hispanic_origin==1)

# fórmula
base$formula_descr <- as.factor(base$formula_descr)

# tamaño
base$size1_descr <- as.factor(base$size1_descr)

# tvs
base$pay_tv <- base$tv_items>1

# internet
base$internet <- base$household_internet_connection==1

base$log_price <- log(base$unit_price+1)

 base_reg<- base[,c("quantity",
                    "log_price",
                    "flavor_descr",
                    "size1_descr",
                    "household_income",
                    "household_size",
                    "coupon",
                    "region",
                    "married",
                    "race",
                    "hispanic_origin",
                    "promotion_type",
                    "age_of_female_head",
                    "age_of_male_head",
                    "age_and_presence_of_children",
                    "male_head_employment",
                    "female_head_employment",
                    "male_head_education","female_head_education",
                    "male_head_occupation",
                    "female_head_occupation",
                    "household_composition",
                    "type_of_residence",
                    "kitchen_appliances",
                    "pay_tv",
                    "internet")]


model_a2<-lm(log(quantity+1) ~ .,data = base_reg)
summary(model_a2)
stargazer(model_a2, type = "text", title="Regresión", digits=1)

```
CORREGIR

Algunos tips: 

- No olvides borrar la variable que recien creamos de sabores. Incluirla (dado que es perfectamente colineal con flavor), sería una violación a supuesto GM 3 de la regresión. 

- No olvides quitar `quantity`, `price_unit`, `price_deal` y otras variables que sirven como identificadora. Tambien quitar `fips_state_code` y `fips_county_code`.

- Empecemos con una regresión que incluya a todas las variables. 


Nota: La regresión en `R` entiende que si le metes variables de texto, debe convertirlas a un factor. En algunos otros algoritmos que veremos durante el curso, tendremos que convertir manualmente toda la base a una númerica. 

Quitemos las fechas
```{r}
base$female_head_birth<-NULL
base$male_head_birth<-NULL
```

### 15 (2 pts). Cuales son los elementos que guarda el objecto de la regresión? Listalos. Cual es el F-test de la regresión? Escribe la prueba de manera matemática (i.e. como la vimos en clase). (Tip: `summary(fit)` te arroja algo del F-test)
````{r}
# para model_a2
(names(model_a2))

glance(model_a2)

RSS <- sum(model_a2$residuals^2)
TSS<- sum((base$quantity-mean(base$quantity))^2)
n<- length(base$unit_price)
k<- sum(!is.na(model_a2$coefficients))

(F <- ((TSS-RSS)/k)/(RSS/(n-k-1)))

summary(model_a2)
```

### 16. Cuál es la elasticidad precio de los helados Ben and Jerry ? Es significativo? Interpreta el coeficiente 
```{r}

# para model_a2
x <- mean(base$unit_price)
y <- mean(base$quantity)
beta <- model_a2$coefficients[2]

elasticity <- beta * (x/y)
# A primera vista sí es significativo
paste("La elasticidad precio de la demanda es de",round(elasticity,2),"%")
paste("Ante un aumento de 1% en el precio, la cantidad demandada se reduce en",round(elasticity,2),"%")

beta2 <- model_a$coefficients[2]
beta2*(y/x)
```

## 17. Cuántos p-values tenemos en la regresión. Haz un histograma de los p-values. 
Tenemos 2, uno para $beta_0$ y otro para $\beta_1$
OJO: CREO QUE SE REFIERE A OTRA COSA, HAY QUE CORRER REGRESION CON TOOOOOOODAS LAS VARAIABLES
````{r}
valores_p <- summary(model_a2)$coefficients[2:k,4]
hist(summary(model_a2)$coefficients[2:k,4])
```


### 18 (4pts). Realiza un ajuste FDR a una $q=0.10$. Grafica el procedimiento (con y sin zoom-in a p-values<0.05). Cuantas variables salían significativas con $\alpha = 0.05$? Cuantas salen con FDR? 
Tip: crea el ranking de cada p-value como `resultados %>% arrange(p.value) %>% mutate(ranking = row_number)`
````{r}
# Función(vector de valores p, q)

fdr <- function(valores_p,q){
  valores_p <- valores_p[!is.na(valores_p)]
  n <<- length(valores_p)
  
  k <- rank (valores_p,ties.method="min")
  t <- valores_p <= q*k/n
  t[valores_p<max(valores_p[t])] <- TRUE
  
  orden <- order(valores_p)
  valores_p_ordenados <<- valores_p[orden]
  plot(valores_p[orden])
  lines(1:n, q*(1:n)/n, col='red')

  return(max(valores_p[t]))
}



q<- 0.05
fdr(valores_p,q)

fdr_save <- fdr(valores_p,q)


plot(valores_p_ordenados,ylim=c(0,q+0.025),xlim=c(0,50))
lines(1:n, q*(1:n)/n,col='red')
abline(h = q)



# prueba
# abc <- c(0.52, 0.07, 0.013, 0.0001, 0.26, 0.04, 0.01, 0.15, 0.03, 0.0002)

# alternativa
fdr2 <- p.adjust(p=valores_p,method="BH")
names(fdr2) <- fdr2 <=0.05
fdr2
```

¿Cuántas variables salían significativas? ¿Cuántas salen con FDR?

```{r}
# Antes
sum(valores_p<0.05)

# Con FDR
sum(valores_p<fdr_save)
```


### 19 (2pts). Repite el ejercicio pero ahora con Holm-Bonferroni. Comparalo vs FDR. En este caso cuantas variables son significativas?  Haz la grafica comparativa (solo con zoom-in)
````{r}

```
