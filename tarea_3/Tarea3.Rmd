---
output:
  pdf_document: null
  geometry: margin=1in
  html_document:
    df_print: paged
fontsize: 11pt
header-includes: \usepackage{geometry} \usepackage{graphicx} \tolerance=1 \hyphenpenalty=10000
  \hbadness=10000 \linespread{1.2} \usepackage[justification=centering, font=bf, labelsep=period,
  skip=5pt]{caption}
  \usepackage{babel} \usepackage{fancyhdr}
  \pagestyle{fancy} \fancyhead[L]{Maestría en Economía Aplicada} \fancyhead[R]{ITAM}
---
\begin{titlepage}
\begin{center}

\textsc{\Large Instituto Tecnológico Autónomo de México}\\[2em]

\textbf{\LARGE Economía Computacional}\\[2em]


\textsc{\LARGE }\\[1em]


\textsc{\LARGE Tarea 3 }\\[1em]
\textsc{\large }\\[1em]
\textsc{\LARGE Equipo 7 }\\[1em]

\textsc{\large }\\[1em]

\textsc{\LARGE Prof. Isidoro García Urquieta}\\[1em]

\textsc{\LARGE }\\[1em]
\textsc{\LARGE }\\[1em]

\textsc{\LARGE Alfredo Lefranc Flores}\\[1em]

\textsc{\large 144346}\\[1em]

\textsc{\LARGE Cynthia Raquel Valdivia Tirado }\\[1em]

\textsc{\large 81358}\\[1em]

\textsc{\LARGE Rafael Sandoval Fernández}\\[1em]

\textsc{\large 143689}\\[1em]

\textsc{\LARGE Marco Antonio Ramos Juárez}\\[1em]

\textsc{\large 142244}\\[1em]

\textsc{\LARGE Francisco Velazquez Guadarrama}\\[1em]

\textsc{\large 175606}\\[1em]

\end{center}

\vspace*{\fill}
\textsc{Ciudad de México \hspace*{\fill} 2021}

\end{titlepage}


\newpage


\tableofcontents

\newpage

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE, warning=FALSE,
                      fig.width = 7, fig.height = 4, fig.align = "right",tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

```{r, include=FALSE}

packages <- c(
  "tidyverse",
  "data.table",
  "broom",
  "knitr",
  "lubridate",
  "RCT",
  "splitstackshape",
  "truncnorm",#para hacer el muestreo estratificado
  "magrittr",
  "kableExtra"
  )

# instala los que no tengas
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# cargar paquetes
lapply(packages,
       library,
       character.only = TRUE)

```



## Contexto

Rappi te contrata para hacer una intervención que active a sus usuarios en la plataforma. La empresa quiere evaluar si es necesario darles cash los usuarios (y cuánto) para reactivar a los usuarios o si es suficiente con una campaña informativa. 

Para ello, te decides a realizar un experimento factorial donde evaluas: 

- El impacto de mandar un mensaje informativo donde muestres las nuevas tiendas afiliadas a Rappi, y 

- El impacto de dar 100 ó 200 o 300 pesos en cupones

Finalmente, les gustaría entender cómo interactuar el mostrar las nuevas tiendas aunado con dar dinero en cupones. 

A la empresa le gustaría entender el impacto de la intervención sobre: 

- Las compras 

- La tasa de usuarios activos en la app (transaccionar: abrir app o hacer compras)

\newpage

## Datos

Los datos para asignar los pueden encontrar en `universo.Rdata`. 

Cargemos los datos
```{r, include=FALSE}
load('universo.Rdata')

data <- universo
rm(universo)

data$population_type <- as.numeric(factor(data$population))
data$device_value_type <- as.numeric(factor(data$device_value))

str(data)

```

### 1. Cuántos grupos de tratamiento debe de haber? Elabora sobre que intervención va a recibir cada uno 

- Control: Ninguna intervención

- Trat 1: Sólo mensaje

- Treat 2: Sólo cupón $100

- Treat 3: Sólo cupón de $200

- Treat 4: Sólo cupón de $300

- Treat 5: Mensaje + $100

- Treat 6: Mensaje + $200

- Treat 7: Mensaje + $300


### 2 (2pts). Como pueden notar, tenemos 2 poblaciones: Usuarios inactivos y usuarios que nunca estuvieron activos. Para ellos, las tasas de transaccionalidad son hasta ahora 7.94% y 0%. Utiliza esta información para hacer pruebas de poder: Dada esta tasa y población, cuál es el efecto mínimo detectable sobre la tasa de transaccionalidad como función de cuantas observaciones asignamos al grupo control? Interpreta. (Tip: asegurate de dejar claros los grupos comparados en esta prueba)

En primer lugar se construye una tabla con el efecto mínimo detectable variando el \textit{share} de control. Para ello se usa $N=$ `r format(round(as.numeric(nrow(data)), 1), nsmall=0, big.mark=",") `, un poder estadístico de 0.8, un nivel de signifancia de 0.05 y los 7 grupos de tratamiento más 1 de control (número de grupos = 8). En segundo lugar se grafica dicha relación para encontrar el valor del  \textit{share} de control que minimice el efecto mínimo detectable. 

```{r}
# Qué es la tasa de transaccionalidad ?
# Respuesta: (transaccionar: abrir app o hacer compras)

data %<>% mutate(tasa_trans = case_when(population_type==1 ~ 0.0794,
                                               T ~ 0))
# =============================
# Tabla
# =============================
tabla_tasa_trans <- tau_min(data$tasa_trans,
                            N = nrow(data),
                            power = 0.8,
                            significance = 0.05,
                            share_control = seq(0,1,0.1),
                            n_groups = 8)

kable(tabla_tasa_trans,booktabs=T, align = 'c',digits = 4)%>%
  kable_styling(position = "center",
                latex_options=c("scale_down","HOLD_position"))
# =============================
# Grafica
# =============================

sharecontrol = seq(0,1,0.05)
m <- matrix(nrow=length(sharecontrol),ncol=1)
n <- matrix(nrow=length(sharecontrol),ncol=1)
i <- 0
for (a in sharecontrol){
  i <- i+1
  taumin<- tau_min(data$tasa_trans,
        N = nrow(data),
        power = 0.8,
        significance = 0.05,
        share_control = a,
        n_groups = 8)
  
m[i] <- taumin$tau_min_global
n[i] <- taumin$tau_min_each_treat
}

m <- cbind(sharecontrol,m,n)
taus <- as.data.frame(m) %>% dplyr::rename("tau_min_global"=V2,"tau_min_each_treat"=V3)
taus_noinf <- taus[-nrow(taus),]
taus_noinf <- taus_noinf[-1,]
share_optimo <- min(taus_noinf$sharecontrol[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])
tau_optima <- min(taus_noinf$tau_min_each_treat[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])

ggplot(data=taus,aes(x=sharecontrol))+
  geom_line(aes(y=tau_min_each_treat*100),color='navyblue',size=1)+
  xlab("Proporción de control")+
  ylab("Efecto mínimo detectable (puntos porcentuales) ")+
  labs(title="Efecto mínimo detectable* (EMD) en función de la proporción de control",
       subtitle="EMD sobre tasa de transaccionalidad",
       caption="*EMD entre el grupo de control y cada tratamiento")+
  scale_x_continuous(breaks = sharecontrol,limits=c(0,1))+
  geom_vline(xintercept= share_optimo, color='red',linetype='dashed')+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, vjust=.5))

```
Se puede observar que para un share de control de `r format(round(as.numeric(share_optimo), 2), nsmall=0, big.mark=",") ` se obtiene el efecto mínimo detectable más pequeño. $\tau=$ `r format(round(as.numeric(tau_optima*100), 4), nsmall=0, big.mark=",")` puntos porcentuales


### 3. Repite el mismo ejercicio pero ahora para usando las compras totales como variable objetivo. Elige un share de control con base en tu respuesta de esta y la anterior pregunta

```{r,results='asis'}

# =============================
# Tabla
# =============================
table_total_purchases <- tau_min(data$total_purchases,
        N = nrow(data),
        power = 0.8,
        significance = 0.05,
        share_control = seq(0,1,0.05),
        n_groups = 8)

kable(table_total_purchases,booktabs=T, align = 'c',digits = 4)%>%
  kable_styling(position = "center",
                latex_options=c("scale_down","HOLD_position"))

# =============================
# Grafica
# =============================
sharecontrol = seq(0,1,0.05) #muy bien
m <- matrix(nrow=length(sharecontrol),ncol=1)
n <- matrix(nrow=length(sharecontrol),ncol=1)

i <- 0
for (a in sharecontrol){
  i <- i+1
  taumin<- tau_min(data$total_purchases,
        N = nrow(data),
        power = 0.8,
        significance = 0.05,
        share_control = a,
        n_groups = 8)
  
m[i] <- taumin$tau_min_global
n[i] <- taumin$tau_min_each_treat
}
m <- cbind(sharecontrol,m,n)
taus <- as.data.frame(m) %>% dplyr::rename("tau_min_global"=V2,"tau_min_each_treat"=V3)
taus_noinf <- taus[-nrow(taus),]
taus_noinf <- taus_noinf[-1,]
share_optimo <- min(taus_noinf$sharecontrol[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])
tau_optima <- min(taus_noinf$tau_min_each_treat[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])

ggplot(data=taus,aes(x=sharecontrol))+
  geom_line(aes(y=tau_min_each_treat),color='navyblue',size=1)+
  xlab("Proporción de control")+
  ylab("Efecto mínimo detectable (número de compras) ")+
  labs(title="Efecto mínimo detectable* (EMD) en función de la proporción de control",
       subtitle="EMD sobre número de compras",
       caption="*EMD entre el grupo de control y cada tratamiento")+
  scale_x_continuous(breaks = sharecontrol,limits=c(0,1))+
  geom_vline(xintercept= share_optimo, color='red',linetype='dashed')+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, vjust=.5))

```

Se puede observar que, nuevamente, para un share de control de `r format(round(as.numeric(share_optimo), 2), nsmall=0, big.mark=",") ` se obtiene el efecto mínimo detectable más pequeño. $\tau=$ `r format(round(as.numeric(tau_optima), 4), nsmall=0, big.mark=",")` compras.

Entonces, usaremos un \textit{share} de control de 0.25 para 



### 4 (2ptos) Qué variables crees que puedan estar más correlacionadas con el impacto? Justifica tu respuesta y elige un set

La verificación del teléfono, ya que probablemente los usuarios que sí llevan a cabo la verificación de sus teléfonos son los que hacen más compras en la aplicación. 

La edad, ya que probablemente usuarios más jóvenes interactúan mejor con las aplicaciones. AQUÍ PODRÍAMOS DEFINIR EDAD POR GRUPOS ?

El valor del telefono

```{r}

# ANALISIS INGENUO A
#en lo que entendimos, hay dos impactos uno para transaccionalidad y otro para las compras
#creo que amerita dos analisis

#ESTE ES UN ANALISIS INGENUO PERO NOS AYUDA A CORRBORAR INTUICION

library(GGally)
data$device_value<-as.factor(data$device_value)
data$population<-as.factor(data$population)

data2 <- sapply(data, as.numeric)
data2<-as.data.frame(data2)
data2<-data2%>% select(device_value, phone_verified,age,
                      population,gender_F,months_since_register,
                      population_type,device_value_type,tasa_trans, total_purchases,)

ggcorr(data2, method = c("everything", "pearson")) 


#para taasa_trans(omitiendo population y populationtype que son colineales) parece que months_since_register,age y phone_verifed esta muy correlacionada.
#En cambio, para total_purchase, ahi si aplica population type esta relacionada. Age tiene una correlacion un poco debil

#ESTE


```

```{r}

# ANALISIS INGENUO B

#converito a factor lo importante
data$phone_verified<-as.factor(data$phone_verified)
data$gender_F<-as.factor(data$gender_F)
data$population_type<-as.factor(data$population_type)
data$device_value_type<-as.factor(data$device_value_type)

modelo_a<-lm(tasa_trans~.-population_type-population-user_id,data)
modelo_b<-lm(total_purchases~.-population_type-population-user_id,data)
#library(stargazer)
stargazer(modelo_a,modelo_b, type="text")
```


```{r}
# V2.0

# Quité device_value porque ya tiene una dummy
reg_a <- lm(tasa_trans ~ . -population_type -population -device_value -user_id, data) 

reg_b <- lm(total_purchases ~ . -population_type -population -device_value -user_id, data = data)
# Acá no quito population_type porque en teoría no se utiliza para llegar a total_purchases
reg_b2 <- lm(total_purchases ~ . -population -device_value -user_id, data = data)

stargazer(reg_a, reg_b, type="text")

# Para tasa_trans: phone_verified, gender, months (chance podríamos jugar con rangos de edad como factor)
# Para total_purchases: phone_verified, gender, months, device_value
```



### 5 (2ptos) Realiza la asignación aleatoria. Muestra la distribución de los grupos por estrato, los misfits. Sin mirar el balance, lograron una asignación aleatoria exitosa? Justifica tu respuesta 

```{r}

# OJO falta ajustar share_control y creo que n_T

random_assignment <- treatment_assign(data=data,
                 share_control = 1/4,
                 n_t=7,
                 strata_varlist = dplyr::vars(population_type,device_value_type,gender_F,phone_verified),
                 missfits="strata",
                 seed=123,
                 key="user_id")

out <- random_assignment$data

data <- left_join(data,out, by =c("user_id"))
```

### 6. Qué elección tomaron sobre como manejar los misfits? Elaboren sus razones

```{r}

# Missfits = strata para mejor balance


```

### 7. Realiza las pruebas de balance t sobre todas las variables (Tip: transforma las categóricas en dummys). Parece haber balance?  

```{r}
# ya las transformé al principio, son las que tienen " _type "
library(fastDummies)
data_3<-data%>%select(population_type,device_value_type,gender_F,phone_verified,treat)
data_4<-dummy_cols(data_3, remove_first_dummy = T,
           select_columns = c('population_type','device_value_type','gender_F','phone_verified'),
           remove_selected_columns = T)

<<<<<<< HEAD
#balance_table()
=======
balance_table(data_4,'treat')
>>>>>>> 3207825107ceec48971c8dc07b8df5137b7ac431

```

### 8. Repite el ejercicio pero ahora con pruebas de balance conjuntas. Muestra los resultados (incluyendo el estadístico de prueba, grados de libertad y p values) Interpreta

```{r}

#balance_table()

```

### 9. Elabora porqué parecen cumplirse los 3 supuestos de la asignación

```{r}

# Aquí creo que se refiere a los siguientes 3:
# 1. SUTVA
# 2. Overlap
# 3. Unconfoundness

```

### 10. Elabora un pitch de negocio sobre los beneficios que este experimento podría dejar a Rappi. 

```{r}

```

## Evaluación 

Pasemos a la evaluación de tu intervención. En este ejercicio, Rappi diseño un nuevo experimento con tus enseñanzas algo distinto al tuyo. 

Este consistió en 6 grupos de tratamiento y un control:

- T1: Dar 100 pesos en cupones (con mensaje)

- T2: Dar 200 pesos en cupones (con mensaje)

- T3: Dar un descuento de 20% en la siguiente compra 

- T4: Dar un descuento de 25% en la siguiente compra

- T5: Ofrecer 2% de descuento en la siguiente compra por cada usuario que refieran

- T6: Ofrecer 4% de descuento en la siguiente compra por cada usuario que refieran


Te piden ahora medir este experimento (estratificado por `phone_verified`, `population` y `device_value`) en la base
`base_evaluacion.Rdata`. Las variables endogenas son `total_purchases_after` que refleja el gasto total post-tratamiento y `transacted` que refleja abrir la app o hacer compras. 


Carguemos la base 

```{r }
rm(list = ls())

load('base_evaluacion.Rdata')
data2 <- universo_f 

rm(universo_f)


data2$population <- as.factor(data2$population)
data2$device_value <- as.factor(data2$device_value)

# bajo esta definicion, population_type: Inactive == 1 y never active == 2
# device_value_type: 0-10mil == 1 | 10mil+ == 2 | No info == 3

# ver como estan definidos los estratos
table(data2$strata)
# 1 a 6 y 1001 a 1006. Son doce grupos, combinaciones de population, device_value y phone_verified
data2$population[data2$strata>10] %>% summary()
data2$phone_verified[data2$strata<4] %>% summary()
data2$phone_verified[data2$strata>1003] %>% summary()
data2$device_value[data2$strata==1 | data2$strata==1001] %>% summary()
data2$device_value[data2$strata==2 | data2$strata==1002] %>% summary()
# 1-6 == Never active
# 1001-1006 == Inactive
# 4-6 y 1004-1006 == phone_verified
# 1, 4, 1001 y 1004: device value == [$0-$10,000]
# 2, 5, 1002 y 1005. device value == [$10,001+]
# 3, 6, 1003 y 1006. device value == No info
```

### 10 (2ptos). Muestra el estimador ITT para la tasa de transaccionalidad. Recuerda que tu cliente es un grupo empresarial. Por ende, muestra una gráfica donde se aprecie la diferencia entre los grupos de tratamiento y las significancias de manera sencilla. Interpreta tus resultados 

```{r}
#ITT intention-to-treat
# OJO, hay que ver si hay que meter heterogenous vars, cluster vars o así
# elección de controles óptima?
# podemos transformar alguna variable?

options(scipen = 999)

itt10 <- impact_eval(data=data2,
            endogenous_vars = "transacted",
            treatment = "treat",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register")) %>%
  as.data.frame()

names(itt10) <- c("term","estimate","std_error","statistic","p_value")
itt10$p_value <- itt10$p_value %>% round(3)
itt10$term <- c("Control", 
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register")

# resultados gráficos
itt10 %>% 
  filter(term!="age" & term != "gender_F" & 
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0("p= ",p_value)), vjust=-0.8, size=3.5)+
  ylim(-0.001,0.12)+
  theme_minimal() +
  labs(title = "Efecto Promedio de Tratamiento en transaccionalidad", 
       x ="",
       caption = "Se controla por edad, sexo, compras totales y meses desde el registro") +
  theme(legend.position="none")

```

### 11. Repite el ejercicio sobre compras totales. Que resultados se aprecian? Que indica esto sobre la rentabilidad del sistema de incentivos? 

```{r}
#ITT intention-to-treat
# OJO, hay que ver si hay que meter heterogenous vars, cluster vars o así

itt11 <- impact_eval(data=data2,
            endogenous_vars = "total_purchases_after",
            treatment = "treat",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register")) %>%
  as.data.frame()

names(itt11) <- c("term","estimate","std_error","statistic","p_value")
itt11$p_value <- itt11$p_value %>% round(3)
itt11$term <- c("Control", 
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register")



```

Parece ser que el tratamiento es efectivo en transaccionalidad pero no en compras.

### 12. Interpreta el impacto del gruop de referidos 4%. Porque el estimador es tan diferente y a la vez es no significativo? Por que esto no paso en la tasa de transaccionalidad?

El estimador es muy grande pero el error estándar es aún más grande, por lo que no es significativo. Esto significa que hay mucha variabilidad en el efecto promedio de tratamiento 6.


```{r}
summary(data2$total_purchases)
summary(data2$total_purchases_after)
```
Hay muchísimos ceros, y el máximo es enorme. Tuvo un gran efecto en pocos, y en muchos no tuvo efecto.


Por la pregunta 13, quizá también tiene que ver con los niveles de compra?

### 13 (2ptos). Repite la medición en 11 pero ahora con `log(total_purchases_after+1)`. Que encuentras ahora? Interpreta las diferencias

Aquí podemos probar meter en logs la de total_purchases como control.

```{r}
#ITT intention-to-treat
# OJO, hay que ver si hay que meter heterogenous vars, cluster vars o así

data2 <- data2 %>% mutate(log_total_purchases_after = log(total_purchases_after+1))

itt13 <- impact_eval(data=data2,
            endogenous_vars = "log_total_purchases_after",
            treatment = "treat",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register")) %>%
  as.data.frame()

names(itt13) <- c("term","estimate","std_error","statistic","p_value")
itt13$p_value <- itt10$p_value %>% round(3)
itt13$term <- c("Control", 
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register")

itt13
```

### 14 (4ptos). Describre que variables necesitas para hacer un análisis costo beneficio completo. Les doy algunas: Ticket promedio $100, Customer Lifetime value: $1,100. Con esto, que sistema de incentivos recomendarías? Porqué? Muestra el razonamiento detrás de tu recomendación

```{r}


```

### 15 (2ptos). Realiza la estimación de efectos heterogeneos para ambas variables usando `population`. Que encuentras? existe alguna subpoblación para la que los efectos difieran del promedio? Para cada efecto, muestra gráficas como lo hiciste en los ITTs

```{r}
itt151 <- impact_eval(data=data2,
            endogenous_vars = "transacted",
            treatment = "treat",
            heterogenous_vars = "population",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))



itt152 <- impact_eval(data=data2,
            endogenous_vars = "log_total_purchases_after",
            treatment = "treat",
            heterogenous_vars = "population",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))


```

### 16 (2ptos). Repite el ejercicio para ``phone_verified`. 

```{r}
itt161 <- impact_eval(data=data2,
            endogenous_vars = "transacted",
            treatment = "treat",
            heterogenous_vars = "phone_verified",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))



itt162 <- impact_eval(data=data2,
            endogenous_vars = "log_total_purchases_after",
            treatment = "treat",
            heterogenous_vars = "phone_verified",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))
```


### 17. Presenta una propuesta de focalización con base en tus resultados generales y heterogeneos. 

```{r}

```

