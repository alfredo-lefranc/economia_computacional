---
output:
  pdf_document: null
  geometry: margin=1in
  html_document:
    df_print: paged
fontsize: 11pt
header-includes: \usepackage{geometry} \usepackage{graphicx} \tolerance=1 \hyphenpenalty=10000
  \hbadness=10000 \linespread{1.2} \usepackage[justification=centering, font=bf, labelsep=period,
  skip=5pt]{caption}
  \usepackage{babel} \usepackage{fancyhdr}
  \pagestyle{fancy} \fancyhead[L]{Maestría en Economía Aplicada} \fancyhead[R]{ITAM}
---
\begin{titlepage}
\begin{center}

\textsc{\Large Instituto Tecnológico Autónomo de México}\\[2em]

\textbf{\LARGE Economía Computacional}\\[2em]


\textsc{\LARGE }\\[1em]


\textsc{\LARGE Tarea 3 }\\[1em]
\textsc{\large }\\[1em]
\textsc{\LARGE Equipo 7 }\\[1em]

\textsc{\large }\\[1em]

\textsc{\LARGE Prof. Isidoro García Urquieta}\\[1em]

\textsc{\LARGE }\\[1em]
\textsc{\LARGE }\\[1em]

\textsc{\LARGE Alfredo Lefranc Flores}\\[1em]

\textsc{\large 144346}\\[1em]

\textsc{\LARGE Cynthia Raquel Valdivia Tirado }\\[1em]

\textsc{\large 81358}\\[1em]

\textsc{\LARGE Rafael Sandoval Fernández}\\[1em]

\textsc{\large 143689}\\[1em]

\textsc{\LARGE Marco Antonio Ramos Juárez}\\[1em]

\textsc{\large 142244}\\[1em]

\textsc{\LARGE Francisco Velazquez Guadarrama}\\[1em]

\textsc{\large 175606}\\[1em]

\end{center}

\vspace*{\fill}
\textsc{Ciudad de México \hspace*{\fill} 2021}

\end{titlepage}


\newpage


\tableofcontents

\newpage

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE, warning=FALSE,
                      fig.width = 7, fig.height = 4, fig.align = "right",tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

```{r, include=FALSE}

packages <- c(
  "tidyverse",
  "data.table",
  "broom",
  "knitr",
  "lubridate",
  "RCT",
  "splitstackshape",
  "truncnorm",#para hacer el muestreo estratificado
  "magrittr",
  "kableExtra",
  "fastDummies",
  "GGally",
  "stargazer",
  "gridExtra"
  )

# instala los paquetes que no se tengan
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# cargar paquetes
lapply(packages,
       library,
       character.only = TRUE)

```



## Contexto

Rappi te contrata para hacer una intervención que active a sus usuarios en la plataforma. La empresa quiere evaluar si es necesario darles cash los usuarios (y cuánto) para reactivar a los usuarios o si es suficiente con una campaña informativa.

Para ello, te decides a realizar un experimento factorial donde evaluas:

- El impacto de mandar un mensaje informativo donde muestres las nuevas tiendas afiliadas a Rappi, y

- El impacto de dar 100 ó 200 o 300 pesos en cupones

Finalmente, les gustaría entender cómo interactuar el mostrar las nuevas tiendas aunado con dar dinero en cupones.

A la empresa le gustaría entender el impacto de la intervención sobre:

- Las compras

- La tasa de usuarios activos en la app (transaccionar: abrir app o hacer compras)

\newpage

## Datos

Los datos para asignar los pueden encontrar en `universo.Rdata`.

Cargemos los datos
```{r, include=FALSE}
load('universo.Rdata')

data <- universo
rm(universo)

data$population_type <- as.numeric(factor(data$population))
data$device_value_type <- as.numeric(factor(data$device_value))

str(data)

```

### 1. Cuántos grupos de tratamiento debe de haber? Elabora sobre que intervención va a recibir cada uno

- Control: Ninguna intervención

- Trat 1: Sólo mensaje

- Treat 2: Sólo cupón $100

- Treat 3: Sólo cupón de $200

- Treat 4: Sólo cupón de $300

- Treat 5: Mensaje + $100

- Treat 6: Mensaje + $200

- Treat 7: Mensaje + $300


### 2 (2pts). Como pueden notar, tenemos 2 poblaciones: Usuarios inactivos y usuarios que nunca estuvieron activos. Para ellos, las tasas de transaccionalidad son hasta ahora 7.94% y 0%. Utiliza esta información para hacer pruebas de poder: Dada esta tasa y población, cuál es el efecto mínimo detectable sobre la tasa de transaccionalidad como función de cuantas observaciones asignamos al grupo control? Interpreta. (Tip: asegurate de dejar claros los grupos comparados en esta prueba)

El efecto mínimo detectable (EMD) representa el efecto que queremos detectar en el experimento dado un nivel de significancia y un poder estadístico. Si nuestro experimento arroja un efecto que es igual o mayor al EMD, entonces tendremos significancia dado el tamaño de la muestra $N$. Si el experimento arroja un efecto menor al EMD, entonces no tendremos significancia.\\

En primer lugar se construye una tabla con el efecto mínimo detectable variando el \textit{share} de control. Para ello se usa $N=$ `r format(round(as.numeric(nrow(data)), 1), nsmall=0, big.mark=",") `, un poder estadístico de 0.8, un nivel de signifancia de 0.05 y los 7 grupos de tratamiento más 1 de control (número de grupos = 8). En segundo lugar se grafica dicha relación para encontrar el valor del  \textit{share} de control que minimice el efecto mínimo detectable.

```{r}
# =============================
# Variable
# =============================

#Agrego una variable con distribucion normal(0.0794,.02) en caso de que sea population_type==1, y 0 en otro caso.
data_2<-data%>%filter(population_type==1) %>% mutate(tasa_trans=rnorm(14084, 0.0794,.02))
data<-merge(data,data_2, all.x = T)
data$tasa_trans[is.na(data$tasa_trans)] <- 0


# =============================
# Tabla
# =============================
tabla_tasa_trans <- tau_min(data$tasa_trans,
                            N = nrow(data),
                            power = 0.8,
                            significance = 0.05,
                            share_control = seq(0,1,0.1),
                            n_groups = 8)

kable(tabla_tasa_trans,booktabs=T, align = 'c',digits = 4)%>%
  kable_styling(position = "center",
                latex_options=c("scale_down","HOLD_position"))
# =============================
# Grafica
# =============================

sharecontrol = seq(0,1,0.05)
m <- matrix(nrow=length(sharecontrol),ncol=1)
n <- matrix(nrow=length(sharecontrol),ncol=1)
i <- 0
for (a in sharecontrol){
  i <- i+1
  taumin<- tau_min(data$tasa_trans,
        N = nrow(data),
        power = 0.8,
        significance = 0.05,
        share_control = a,
        n_groups = 8)

m[i] <- taumin$tau_min_global
n[i] <- taumin$tau_min_each_treat
}

m <- cbind(sharecontrol,m,n)
taus <- as.data.frame(m) %>% dplyr::rename("tau_min_global"=V2,"tau_min_each_treat"=V3)
taus_noinf <- taus[-nrow(taus),]
taus_noinf <- taus_noinf[-1,]
share_optimo <- min(taus_noinf$sharecontrol[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])
tau_optima <- min(taus_noinf$tau_min_each_treat[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])

ggplot(data=taus,aes(x=sharecontrol))+
  geom_line(aes(y=tau_min_each_treat*100),color='navyblue',size=1)+
  xlab("Proporción de control")+
  ylab("Efecto mínimo detectable (puntos porcentuales) ")+
  labs(title="Efecto mínimo detectable* (EMD) en función de la proporción de control",
       subtitle="EMD sobre tasa de transaccionalidad",
       caption="*EMD entre el grupo de control y cada tratamiento")+
  scale_x_continuous(breaks = sharecontrol,limits=c(0,1))+
  geom_vline(xintercept= share_optimo, color='red',linetype='dashed')+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, vjust=.5))

```
Se puede observar que para un share de control de `r format(round(as.numeric(share_optimo), 2), nsmall=0, big.mark=",") ` se obtiene el efecto mínimo detectable más pequeño. $\tau=$ `r format(round(as.numeric(tau_optima*100), 4), nsmall=0, big.mark=",")` puntos porcentuales entre el grupo de control y cada tratamiento.






### 3. Repite el mismo ejercicio pero ahora para usando las compras totales como variable objetivo. Elige un share de control con base en tu respuesta de esta y la anterior pregunta

```{r,results='asis'}

# =============================
# Tabla
# =============================
table_total_purchases <- tau_min(data$total_purchases,
        N = nrow(data),
        power = 0.8,
        significance = 0.05,
        share_control = seq(0,1,0.05),
        n_groups = 8)

kable(table_total_purchases,booktabs=T, align = 'c',digits = 4)%>%
  kable_styling(position = "center",
                latex_options=c("scale_down","HOLD_position"))

# =============================
# Grafica
# =============================
sharecontrol = seq(0,1,0.05) #muy bien
m <- matrix(nrow=length(sharecontrol),ncol=1)
n <- matrix(nrow=length(sharecontrol),ncol=1)

i <- 0
for (a in sharecontrol){
  i <- i+1
  taumin<- tau_min(data$total_purchases,
        N = nrow(data),
        power = 0.8,
        significance = 0.05,
        share_control = a,
        n_groups = 8)

m[i] <- taumin$tau_min_global
n[i] <- taumin$tau_min_each_treat
}
m <- cbind(sharecontrol,m,n)
taus <- as.data.frame(m) %>% dplyr::rename("tau_min_global"=V2,"tau_min_each_treat"=V3)
taus_noinf <- taus[-nrow(taus),]
taus_noinf <- taus_noinf[-1,]
share_optimo <- min(taus_noinf$sharecontrol[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])
tau_optima <- min(taus_noinf$tau_min_each_treat[taus_noinf$tau_min_each_treat==min(taus_noinf$tau_min_each_treat)])

ggplot(data=taus,aes(x=sharecontrol))+
  geom_line(aes(y=tau_min_each_treat),color='navyblue',size=1)+
  xlab("Proporción de control")+
  ylab("Efecto mínimo detectable (número de compras) ")+
  labs(title="Efecto mínimo detectable* (EMD) en función de la proporción de control",
       subtitle="EMD sobre número de compras",
       caption="*EMD entre el grupo de control y cada tratamiento")+
  scale_x_continuous(breaks = sharecontrol,limits=c(0,1))+
  geom_vline(xintercept= share_optimo, color='red',linetype='dashed')+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, vjust=.5))

```

Se puede observar que, nuevamente, para un share de control de `r format(round(as.numeric(share_optimo), 2), nsmall=0, big.mark=",") ` se obtiene el efecto mínimo detectable más pequeño. $\tau=$ `r format(round(as.numeric(tau_optima), 4), nsmall=0, big.mark=",")` compras entre el grupo de control y cada tratamiento

Entonces, usaremos un \textit{share} de control de 0.25 para



### 4 (2ptos) Qué variables crees que puedan estar más correlacionadas con el impacto? Justifica tu respuesta y elige un set

Inicialmente se realiza un análisis para el cual es fundamental mantener en mente que su principal función es servir de apoyo, no para obtener conclusiones directas. Esto se debe a que, en realidad, lo que es de interés para la estratificación es la relación entre las variables por las cuales se estratifica y el impacto, no con la tasa de usuarios activos o las ventas. Se procede a mostrar un correlograma y una regresión lineal (que aún existiendo un problema metodológico podría ser útil para este fin).

```{r}
# Se prepara la base

# Categorizo las categoricas
data$phone_verified<-as.factor(data$phone_verified)
data$gender_F<-as.factor(data$gender_F)
data$population_type<-as.factor(data$population_type)
data$device_value_type<-as.factor(data$device_value_type)

# Creo todo numerico (con base en dummies)
data_correctly<-data%>%select(-user_id)
data_correctly<-dummy_cols(data_correctly, remove_first_dummy = F,
           select_columns = c('device_value','phone_verified','population','gender_F','population_type','device_value_type'),
           remove_selected_columns = T)

#imprimo el correlograma
ggcorr(data_correctly, method = c("everything", "pearson"), label = TRUE,max_size = 6,
  size = 3,
  hjust = 0.75,
  angle = -45)
#Evidentemente hay colinealidad perfecta en algunas variables, entonces cuidado al interpretar esto.

```


```{r}
# Se crean categorías para distintos rangos de edad a partir de los cuartiles
age_quart <- quantile(data$age)
data$age_group <- ifelse(data$age <= age_quart[2], 1,
                         ifelse(data$age <= age_quart[3], 2,
                                ifelse(data$age <= age_quart[4], 3,
                                       ifelse(data$age <= age_quart[5], 4, 0))))
data$age_group <- as.factor(data$age_group)

# REGRESION
# Quito las variables colineales y las objetivo
modelo_a<-lm(tasa_trans~.-population_type-population-user_id-total_purchases-age-device_value,data)

modelo_b<-lm(total_purchases~.-population_type-population-user_id-tasa_trans-age-device_value,data)

stargazer(modelo_a,modelo_b, type="latex")
```


Ahora, se plantean variables por las cuales se estratificará, y se comenta si existe coherencia con el análisis:

* La verificación del teléfono, ya que probablemente los usuarios que sí llevan a cabo la verificación de sus teléfonos son los que hacen más compras en la aplicación. Si hacen pedidos con frecuencia, tiene sentido que les interese que el número de teléfono registrado sea el correcto para cualquier llamada respecto a su pedido. Notamos cómo es una variable significativa y relativamente importante en cada modelo.

* La edad (dividida por categorías para distintos rangos), ya que probablemente usuarios más jóvenes interactúan mejor con las aplicaciones. Notamos que cumple con los mismos puntos respecto a las regresiones que la variable anterior. Nótese que posiblemente sea una buena idea formar rangos más amplios para no tener que pulverizar tanto las observaciones (en este caso se utilizan cuartiles). En este sentido, proponemos solamente agrupar la edad en dos grupos, la mitad más grande y la mitad más jóven.

* Si bien no se considera la variable para los modelos anteriores por problemas de colinealidad, resulta intuitivo pensar que un usuario poco activo pueda verse incentivado a por lo menos abrir la aplicación al recibir cupones y/o notificaciones, y que este comportamiento seguramente es distinto al de un individo que jamás utiliza la aplicación. Por este motivo, population podría resultar también relevante.

* Consideramos que si bien el género no nos dice mucho per se, puede tener un impacto combinado con las demás variables. Por ejemplo, de correr una regresión sobre nuestras Ys con los grupos de edad, notamos que si hay un comportamiento heterogéneo por edad y por sexo.

```{r}
modelo_a<-lm(tasa_trans~age_group+gender_F+I(age_group:gender_F),data)

modelo_b<-lm(total_purchases~age_group+gender_F+I(age_group:gender_F),data)

stargazer(modelo_a,modelo_b, type="latex")
```


* Ahora bien, nos hubiera gustado incluir el valor del telefono, ya que podría servir como un proxy para medir el nivel de ingresos del individuo, sin embargo, notamos que esta variable es muy ruidosa. En primer lugar aglomera las observaciones en dos grupos principales (celulares de 0 a 10,000 pesos y Sin información) y un grupo minoritario con solo 74 observaciones (celulares de un precio mayor a 10,000). Si bien podriamos agrupar esas 74 observaciones dentro de Sin información, al correr una regresión sobre nuestras Ys notamos que el grupo sin informacion en realidad tiene un impacto negativo y significativo sobre las variables, lo cual puede indicar que son personas con un celular de bajo costo que bien podría ubicarse en el grupo de 0 a 10,000 (debido a que es muy amplio). Agrupar aqui al grupo minoritario sería solo crear ruido sobre una variable que de por sí cuenta con categorias muy amplias y vagas en sí.

```{r}
modelo_a<-lm(tasa_trans~device_value,data)

modelo_b<-lm(total_purchases~device_value,data)

stargazer(modelo_a,modelo_b, type="latex")
```


### 5 (2ptos) Realiza la asignación aleatoria. Muestra la distribución de los grupos por estrato, los misfits. Sin mirar el balance, lograron una asignación aleatoria exitosa? Justifica tu respuesta

```{r}

#Agrupo la variable de edad para que sea una dummy que discrimine a la mitad más jóven de la más grande.
data<-data%>%mutate(age_dummy=ifelse(age_group==1|2,0,1))

# =============================
# Asignacion
# =============================
random_assignment <- treatment_assign(data=data,
                 share_control = 1/4,
                 n_t=7,
                 strata_varlist = dplyr::vars(population_type,phone_verified,age_dummy, gender_F),
                 missfits="global",
                 seed=123,
                 key="user_id")

out <- random_assignment$data
# agrego asignación en la base de datos
data<-merge(data,out, by= "user_id")


# =============================
# Tablas
# =============================

out_no_misfits_summary<-out%>% filter(missfit==0)%>%
        group_by(strata) %>% 
        summarize(n())

strats<-out%>% filter(missfit==0)%>%
        group_by(strata,treat) %>% 
        summarize(n()) %>% 
        mutate(p=ifelse(strata==1,`n()`/3640,
                  ifelse(strata==2,`n()`/1848, 
                  ifelse(strata==3,`n()`/5544,
                  ifelse(strata==4,`n()`/2996,
                  ifelse(strata==5,`n()`/42616,
                  ifelse(strata==6,`n()`/12320,
                  ifelse(strata==7,`n()`/26180,
                  ifelse(strata==8,`n()`/8932,)))))))))
kable(strats,col.names = c("Estrato","Tratamiento","n","Probabilidad"))
```
Todo parece indicar que se logró una asignación aleatoria exitosa toda vez que se conoce la función de asignación la cual cumple con los 3 requisitos (asignación individual, probabilística y unconfoundness). Como podemos ver en la tabla anterior, dentro de cada estrato (sin misfists) la probabilidad de pertenecer a cada grupo es la misma que habiamos definido en el comando (.25 para control y el .107 para los tratamientos)

### 6. Qué elección tomaron sobre como manejar los misfits? Elaboren sus razones

Si bien el número de misfits es muy bajo relativo al total de observaciones (115 solamente) y podrían eliminarse, elegimos asignar los misfits de manera global, pues es posible que se haya asignado un presupuesto fijo para hacer el experimento, por lo que es importante que las probabilidades agregadas por grupo sean exactas. Asimismo, nótese cómo el posible desbalance causado por este método resulta negligible al considerar que el número de misfits es relativamente chico.

```{r}

# =============================
# Tablas de misfits
# =============================

out_misfits_summary<-out%>% filter(missfit==1)%>%
        group_by(strata) %>% 
        summarize(n())

m_t<-out%>% filter(missfit==1)%>%
        group_by(treat) %>% 
        summarize(n())

kable(out_misfits_summary, col.names = c("Estrato","n"))
kable(m_t,col.names=c("Tratamiento","n"))


```

### 7. Realiza las pruebas de balance t sobre todas las variables (Tip: transforma las categóricas en dummys). Parece haber balance?  

```{r}


# Selecciono solo las variables que use para estratificar
data_3<-data%>%select(population_type,device_value_type,gender_F,phone_verified,treat)
data_4<-dummy_cols(data_3, remove_first_dummy = T,
           select_columns = c('population_type','device_value_type','gender_F','phone_verified'),
           remove_selected_columns = T)

# Imprimo las tablas de balance
balance_table(data_4,'treat')
#Parece haber balance debido a que ningun pvalue es estadisticamente significativo. Las medias son muy similares.
```

### 8. Repite el ejercicio pero ahora con pruebas de balance conjuntas. Muestra los resultados (incluyendo el estadístico de prueba, grados de libertad y p values) Interpreta

```{r}
balance_regression(data_4, 'treat')
```

### 9. Elabora porqué parecen cumplirse los 3 supuestos de la asignación


```{r}
# FVG: Confirmo, sólo podría cambiar el número de bloques. Haces un buen punto y argumento en favor de mejor asignar misfits por estrato y no global como sugerí en la 6.
# Aquí creo que se refiere a los siguientes 3:
# 1. SUTVA # En principio cada mensaje y bono va direccionado al celular individual de cada persona, SUTVA solo se violaria si otra persona tiene acceso al celular o a la cuenta de alguien en un grupo de tratamiento. En consecuencia, dado que no hay posibilidad de que los usuarios que recibieron tratamiento -que recibieron mensaje o r dinero a través de cupones- afecten al grupo de usuarios que no lo recibió, no hay contaminación entre los  grupos.
# 2. Overlap # Forzamos a que cada estrato tuviera 8 grupos, la probabilidad de pertenecer a uno es aproximadamente 1/8 siempre, es decir, siempre positiva, dentro del intervalo (0,1) pero diferente de 0 y 1.
# 3. Unconfoundness # Los grupos estan balanceados (por construccion), las tablas de balance solo comprueban este supuesto.


#R: duda, nos quedamos con asignación de missfits global o por estrato ?
```

### 10. Elabora un pitch de negocio sobre los beneficios que este experimento podría dejar a Rappi.

Para garantizar el éxito de un negocio, previo a ir en búsqueda de más clientes, es indispensable proteger a los que ya se tiene. A través de este experimento se logran detectar las características esenciales de los usuarios que han disminuido su actividad o que se registraron pero nunca han utilizado la plataforma, con el fin de encontrar la fórmula ideal de incentivos -envío de mensajes publicitarios, cupones o ambos- que generen un impacto en cada grupo de clientes para retomar su interés y actividad en la aplicación y  volverse ávidos usuarios de la plataforma, incrementar sus compras y con ello lograr aumentar las ganancias de la empresa. No más usuarios dormidos o apáticos, por el contrario, siempre interactuando y generando valor para la empresa.



## Evaluación

Pasemos a la evaluación de tu intervención. En este ejercicio, Rappi diseño un nuevo experimento con tus enseñanzas algo distinto al tuyo.

Este consistió en 6 grupos de tratamiento y un control:

- T1: Dar 100 pesos en cupones (con mensaje)

- T2: Dar 200 pesos en cupones (con mensaje)

- T3: Dar un descuento de 20% en la siguiente compra

- T4: Dar un descuento de 25% en la siguiente compra

- T5: Ofrecer 2% de descuento en la siguiente compra por cada usuario que refieran

- T6: Ofrecer 4% de descuento en la siguiente compra por cada usuario que refieran


Te piden ahora medir este experimento (estratificado por `phone_verified`, `population` y `device_value`) en la base
`base_evaluacion.Rdata`. Las variables endogenas son `total_purchases_after` que refleja el gasto total post-tratamiento y `transacted` que refleja abrir la app o hacer compras.


Carguemos la base

```{r }
rm(list = ls())

load('base_evaluacion.Rdata')
data2 <- universo_f

rm(universo_f)


data2$population <- as.factor(data2$population)
data2$device_value <- as.factor(data2$device_value)

# bajo esta definicion, population: Inactive == 1 y never active == 2
# device_value: 0-10mil == 1 | 10mil+ == 2 | No info == 3

# ver como estan definidos los estratos
table(data2$strata)
# 1 a 6 y 1001 a 1006. Son doce grupos, combinaciones de population, device_value y phone_verified
data2$population[data2$strata>10] %>% summary()
data2$phone_verified[data2$strata<4] %>% summary()
data2$phone_verified[data2$strata>1003] %>% summary()
data2$device_value[data2$strata==1 | data2$strata==1001] %>% summary()
data2$device_value[data2$strata==2 | data2$strata==1002] %>% summary()
# 1-6 == Never active
# 1001-1006 == Inactive
# 4-6 y 1004-1006 == phone_verified
# 1, 4, 1001 y 1004: device value == [$0-$10,000]
# 2, 5, 1002 y 1005. device value == [$10,001+]
# 3, 6, 1003 y 1006. device value == No info
```

### 10 (2ptos). Muestra el estimador ITT para la tasa de transaccionalidad. Recuerda que tu cliente es un grupo empresarial. Por ende, muestra una gráfica donde se aprecie la diferencia entre los grupos de tratamiento y las significancias de manera sencilla. Interpreta tus resultados

```{r}
#ITT intention-to-treat
# OJO, hay que ver si hay que meter heterogenous vars, cluster vars o así
# elección de controles óptima?
# podemos transformar alguna variable?

options(scipen = 999)

itt10 <- impact_eval(data=data2,
            endogenous_vars = "transacted",
            treatment = "treat",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register")) %>%
  as.data.frame()

names(itt10) <- c("term","estimate","std_error","statistic","p_value")
itt10$p_value <- itt10$p_value %>% round(3)
itt10$term <- c("Control",
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register")

# resultados gráficos
itt10 %>%
  filter(term!="age" & term != "gender_F" &
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0("p= ",p_value)), vjust=-0.8, size=3.5)+
  ylim(-0.001,0.12)+
  theme_minimal() +
  labs(title = "Efecto Promedio de Tratamiento en transaccionalidad",
       x ="",
       caption = "Se controla por edad, sexo, compras totales y meses desde el registro") +
  theme(legend.position="none")

```
Se observan efectos promedio de los seis tratamientos positivos y significativos. El efecto entre tratamientos varía. El tratamiento con mayor impacto en la transaccionalidad es ofrecer un 25% de descuento en la siguiente compra, lo cual provoca un aumento de 10 puntos porcentuales. Ofrecer 4% de descuento por cada referido también tuvo un impacto mayor a 7.5 puntos porcentuales. Como es de esperarse, la magnitud del efecto es proporcional al tamaño del descuento. Esto es visible al contrastar los tratamientos 2, 4 y 6 con el 1, 3 y 5, respectivamente. Es curioso que, los descuentos en porcentaje fueran más exitosos que los \$100 y \$200. Esto podría reflejar que los usuarios aprovechan el beneficio con compras grandes, lo cual exploramos a continuación.


### 11. Repite el ejercicio sobre compras totales. Que resultados se aprecian? Que indica esto sobre la rentabilidad del sistema de incentivos?

```{r}
#ITT intention-to-treat
# OJO, hay que ver si hay que meter heterogenous vars, cluster vars o así

itt11 <- impact_eval(data=data2,
            endogenous_vars = "total_purchases_after",
            treatment = "treat",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register")) %>%
  as.data.frame()

names(itt11) <- c("term","estimate","std_error","statistic","p_value")
itt11$p_value <- itt11$p_value %>% round(3)
itt11$term <- c("Control",
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register")

# resultados gráficos
itt11 %>%
  filter(term!="age" & term != "gender_F" &
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0("p= ",p_value)), vjust=-0.8, size=3.5)+
  ylim(-50,120)+
  theme_minimal() +
  labs(title = "Efecto Promedio de Tratamiento en compras totales",
       x ="",
       caption = "Se controla por edad, sexo, compras totales y meses desde el registro") +
  theme(legend.position="none")

```

Como puede verse en la gráfica, los tratamientos 1 a 5 son negativos y ninguno de los efectos de tratamiento es significativo. Considerando estos resultados junto con los de transaccionalidad, se concluye que los incentivos de descuentos atraen a los usuarios a la app, pero no capitalizan comprando más que antes. También debe notarse que independientemente del monto de los descuentos, omitiendo los descuentos por referir personas, tienen coeficientes muy parecidos, por lo que parece no haber relación entre el monto del descuento y el impacto en compras.

Esta evidencia indica que el sistema de incentivos de Rappi no es rentable, por lo menos no en el periodo de estudio. Es posible que los usuarios deban recibir más de un descuento para terminar por volverse usuarios frecuentes de la app, y que de recibir un sólo descuento el efecto sea muy débil.

**DUDA. TOTAL PURCHASES AFTER incluye los montos de los descuentos? o es el monto de compras que paga el usuario, neto de cualquier código de descuento que pongan?**


### 12. Interpreta el impacto del gruop de referidos 4%. Porque el estimador es tan diferente y a la vez es no significativo? Por que esto no paso en la tasa de transaccionalidad?

El estimador es muy grande pero el error estándar es aún más grande, por lo que no es significativo. Esto quiere decir que hay mucha variabilidad en el efecto promedio de tratamiento 6.


```{r}
summary(data2$total_purchases)
summary(data2$total_purchases_after)
```
Hay muchísimos ceros, y el máximo es enorme. Tuvo un gran efecto en pocos, y en muchos no tuvo efecto.


Por la pregunta 13, quizá también tiene que ver con los niveles de compra?

### 13 (2ptos). Repite la medición en 11 pero ahora con `log(total_purchases_after+1)`. Que encuentras ahora? Interpreta las diferencias

Aquí podemos probar meter en logs la de total_purchases como control.

```{r}
#ITT intention-to-treat
# OJO, hay que ver si hay que meter heterogenous vars, cluster vars o así

data2 <- data2 %>% mutate(log_total_purchases_after = log(total_purchases_after+1))

itt13 <- impact_eval(data=data2,
            endogenous_vars = "log_total_purchases_after",
            treatment = "treat",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register")) %>%
  as.data.frame()

names(itt13) <- c("term","estimate","std_error","statistic","p_value")
itt13$p_value <- itt13$p_value %>% round(3)
itt13$term <- c("Control",
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register")

# resultados gráficos
itt13 %>%
  filter(term!="age" & term != "gender_F" &
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0("p= ",p_value)), vjust=-0.8, size=3.5)+
  theme_minimal() +
  ylim(0,0.2)+
  labs(title = "Efecto Promedio de Tratamiento en compras totales (log)",
       x ="",
       caption = "Se controla por edad, sexo, compras totales y meses desde el registro") +
  theme(legend.position="none")
```

El tratamiento 6, el ofrecer 4% de descuento en la siguiente compra por cada usuario que refieran, resultó tener mayor impacto cuando la variable de las compras totales posteriores se usa en forma logarítmica, probablemente porque se vuelve más estable y se suavizan los outliers que pudieran estar influyendo sobre el impacto en la variable original.  

### 14 (4ptos). Describre que variables necesitas para hacer un análisis costo beneficio completo. Les doy algunas: Ticket promedio $100, Customer Lifetime value: $1,100. Con esto, que sistema de incentivos recomendarías? Porqué? Muestra el razonamiento detrás de tu recomendación

Variables necesarias para el costo beneficio de los primeros 4 tratamientos:

+ Ticket promedio ($100)
+ Customer lifetime value
+ Costo por mensaje
+ Promedio del margen de ganancia por ticket
+ Porcentaje de usuarios invitados que sí aprovechan la promoción


Variables adicionales para el costo beneficio de los últimos 2 tratamientos:

+ Promedio de compras por usuario
+ Probabilidad de que el usuario sea activo (activos/inactivos)
+ Porcentaje de usuarios que hacen efectivas las compras


Recomendaríamos  el 6 porque ofrecer un descuento de 4% en una compra es sustancialmente menos costoso que los otros, y porque el lifetime value del customer no es muy grande. Es más rentable apuntar al volumen que al precio, y buscar incrementar la base de usuarios parece ser una mejor estrategia. Preferimos el tratamiento 6 por encima del 5 porque el 6 tiene un efecto positivo en las compras de los clientes, mientras que no se puede asegurar lo mismo para el 5.

Es posible respaldar lo anterior, ya que si un cliente desembolsara en promedio 100 pesos en cada compra; con la estrategia 6 esto implicaría que por haber referido a un nuevo usuario, se le dará un 4% de descuento en la compra siguiente, esto es 4 pesos de descuento en promedio por una nueva compra, por lo que esta estrategia resulta ser rentable. El costo de adquirir un nuevo cliente potencial es \$4 y su CLTV es de \$1100, lo que implica que su adquisición resulta lucrativa. 

Por el contrario, en el caso del tratamiento 4, por ejemplo, al otorgar un descuento del 25% en la siguiente compra, el costo del descuento incluso podría superar el CLTV del usuario, dependiendo del monto de la compra. 




### 15 (2ptos). Realiza la estimación de efectos heterogeneos para ambas variables usando `population`. Que encuentras? existe alguna subpoblación para la que los efectos difieran del promedio? Para cada efecto, muestra gráficas como lo hiciste en los ITTs

```{r}

# Estimaciones
itt151 <- impact_eval(data=data2,
            endogenous_vars = "transacted",
            treatment = "treat",
            heterogenous_vars = "population",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))

itt152 <- impact_eval(data=data2,
            endogenous_vars = "log_total_purchases_after",
            treatment = "treat",
            heterogenous_vars = "population",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))

# Ediciones pre grafica
pop_trans <- itt151$transacted_population %>% as.data.frame()

pop_trans$p.value <- pop_trans$p.value %>% round(3)
pop_trans$term <- rep(c("Control",
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register"),2)

pop_compras <- itt152$log_total_purchases_after_population %>% as.data.frame()

pop_compras$p.value <- pop_compras$p.value %>% round(3)
pop_compras$term <- rep(c("Control",
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register"),2)


# resultados gráficos

row151 <- pop_trans %>%
  filter(term!="age" & term != "gender_F" &
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  facet_wrap(~population)+
  ylim(-0.02,0.2)+
  geom_text(aes(label=paste0("p=",p.value)), vjust=-0.8, size=3, alpha=0.6) +
  labs(title = "Transaccionalidad",
       x ="") +
  theme(legend.position="none",
        plot.title = element_text(size=10, hjust=0.5))

row152 <- pop_compras %>%
  filter(term!="age" & term != "gender_F" &
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  facet_wrap(~population)+
  ylim(-0.15,0.3)+
  geom_text(aes(label=paste0("p=",p.value)), vjust=-0.8, size=3, alpha=0.6) +
  labs(title="Compras totales (log)",
       x="")+
  theme(legend.position="none",
        plot.title = element_text(size=10, hjust=0.5))

grid.arrange(row151,row152, ncol=1,
             top = "Efectos Promedio de Tratamiento por Población",
             bottom = "Se controla por edad, sexo, compras totales y meses desde el registro")

```
Como era de esperarse, para los usuarios que nunca estuvieron activos (never actives), el impacto del tratamiento (mensajes y descuentos) es mayor en la tasa de transacción dado que nunca habían registrado actividad en la plataforma, a diferencia de los que ya habían iteractuado pero dejaron de hacerlo (inactivos). En particular para los never actives, los tratamientos 3, 4 y 6 superan el promedio. 

En cuanto al impacto en las compras totales, el resultado fue híbrido, por una parte para la población que nunca estuvo activa, el impacto fue mayor en los tratamientos 3 y 6 y para la población inactiva los tratamientos que tuvieron mayor impacto fueron los 6 y 2 (por arriba del promedio). 

### 16 (2ptos). Repite el ejercicio para ``phone_verified`.

```{r}
# Estimaciones
itt161 <- impact_eval(data=data2,
            endogenous_vars = "transacted",
            treatment = "treat",
            heterogenous_vars = "phone_verified",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))

itt162 <- impact_eval(data=data2,
            endogenous_vars = "log_total_purchases_after",
            treatment = "treat",
            heterogenous_vars = "phone_verified",
            control_vars = c("age",
                             "gender_F",
                             "total_purchases",
                             "months_since_register"))

# Ediciones pre grafica
phone_trans <- itt161$transacted_phone_verified %>% as.data.frame()

phone_trans$p.value <- phone_trans$p.value %>% round(3)
phone_trans$term <- rep(c("Control",
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register"),2)

phone_compras <- itt162$log_total_purchases_after_phone_verified %>% as.data.frame()

phone_compras$p.value <- phone_compras$p.value %>% round(3)
phone_compras$term <- rep(c("Control",
                "Treat1", "Treat2", "Treat3", "Treat4", "Treat5", "Treat6",
                "age",
                "gender_F",
                "total_purchases",
                "months_since_register"),2)

#convertir phone_verified a factor
summary(data2$phone_verified)
data2$phone_verified <- data2$phone_verified %>% as.factor
levels(data2$phone_verified) <- c("not verified", "verified")



# resultados gráficos

row161 <- phone_trans %>%
  filter(term!="age" & term != "gender_F" &
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  facet_wrap(~phone_verified)+
  ylim(-0.001,0.18)+
  geom_text(aes(label=paste0("p=",p.value)), vjust=-0.8, size=3, alpha=0.6) +
  labs(title = "Transaccionalidad",
       x ="") +
  theme(legend.position="none",
        plot.title = element_text(size=10, hjust=0.5))

row162 <- phone_compras %>%
  filter(term!="age" & term != "gender_F" &
           term!="total_purchases" & term != "months_since_register") %>%
ggplot(aes(y=estimate, x=term, fill=term)) +
  geom_bar(stat="identity") +
  facet_wrap(~phone_verified)+
  ylim(-0.06,0.5)+
  geom_text(aes(label=paste0("p=",p.value)), vjust=-0.8, size=3, alpha=0.6) +
  labs(title="Compras totales (log)",
       x="")+
  theme(legend.position="none",
        plot.title = element_text(size=10, hjust=0.5))

grid.arrange(row161,row162, ncol=1,
             top = "Efectos Promedio de Tratamiento por Verificación del Teléfono",
             bottom = "Se controla por edad, sexo, compras totales y meses desde el registro")
```

En general, para los usuarios que verificaron su celular, el impacto de los tratamientos en las transacciones es mayor que para aquellos que no, lo cual resulta lógico en el sentido de que aquellos que verificaron sus teléfonos, probablemente tenían más interés en el uso de la plataforma que los que no lo hicieron. Sólo el tratamiento 5, resultó con mayor mayor impacto para quienes no verificaron su número. 

En cuanto a las compras totales, se observa que el tratamiento 6 fue el que tuvo mucho mayor impacto para aquellos que verificaron su celular.


### 17. Presenta una propuesta de focalización con base en tus resultados generales y heterogeneos.

```{r}

```
