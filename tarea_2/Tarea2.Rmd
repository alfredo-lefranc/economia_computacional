---
output:
  pdf_document: null
  geometry: margin=1in
  html_document:
    df_print: paged
fontsize: 11pt
header-includes: \usepackage{geometry} \usepackage{graphicx} \tolerance=1 \hyphenpenalty=10000
  \hbadness=10000 \linespread{1.2} \usepackage[justification=centering, font=bf, labelsep=period,
  skip=5pt]{caption} \usepackage{titling} \usepackage{babel} \usepackage{fancyhdr}
  \pagestyle{fancy} \fancyhead[L]{Maestría en Economía Aplicada} \fancyhead[R]{ITAM}
---
\begin{titlepage}
\begin{center}

\textsc{\Large Instituto Tecnológico Autónomo de México}\\[2em]

\textbf{\LARGE Economía Computacional}\\[2em]


\textsc{\LARGE }\\[1em]


\textsc{\LARGE Tarea 2 }\\[1em]
\textsc{\large }\\[1em]
\textsc{\LARGE Equipo 7 }\\[1em]


\textsc{\large }\\[1em]
\textsc{\LARGE }\\[1em]


\textsc{\large }\\[1em]
\textsc{\LARGE }\\[1em]

\textsc{\LARGE Prof. Isidoro García Urquieta}\\[1em]

\textsc{\LARGE }\\[1em]
\textsc{\LARGE }\\[1em]

\textsc{\LARGE Alfredo Lefranc Flores}\\[1em]

\textsc{\large 144346}\\[1em]

\textsc{\LARGE Cynthia Raquel Valdivia Tirado }\\[1em]

\textsc{\large 81358}\\[1em]

\textsc{\LARGE Rafael Sandoval Fernández}\\[1em]

\textsc{\large 143689}\\[1em]

\textsc{\LARGE Marco Antonio Ramos Juárez}\\[1em]

\textsc{\large 142244}\\[1em]

\textsc{\LARGE Francisco Velazquez Guadarrama}\\[1em]

\textsc{\large 175606}\\[1em]

\end{center}

\vspace*{\fill}
\textsc{Ciudad de México \hspace*{\fill} 2021}

\end{titlepage}


\newpage


\tableofcontents

\newpage

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE,
                      fig.width = 7, fig.height = 4, fig.align = "right")
```

```{r, message=FALSE}
packages <- c(
  "tidyverse",
  "data.table",
  'broom',
  'knitr',
  'lubridate',
  'RCT',
  'gamlr',
  'ranger',
  'tree',
  'parallel',
  'naniar',
  'kableExtra',
  'gridExtra',
  'VIM',
  'smotefamily'
  )

# instala los que no tengas
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# cargar paquetes
lapply(packages,
       library,
       character.only = TRUE)

# funciones

check_nas <- function(df){
  df %>%
    select_if(~sum(is.na(.)) > 0) %>%
    miss_var_summary()
}

```



## Contexto

Cell2Cell es una compañía de teléfonos celulares que intenta mitigar el abandono de sus usuarios. Te contratan para 1) Encontrar un modelo que prediga el abandono con acierto y para usar los insights de este modelo para proponer una estrategia de manejo de abandono.


Las preguntas que contestaremos son:

1. Se puede predecir el abandono con los datos que nos compartieron?

2. Cuáles son las variables que explican en mayor medida el abandono?

3. Qué incentivos da Cell2Cell a sus usarios para prevenir el abandono?

4. Cuál es el valor de una estrategia de prevención de abandono focalizada y cómo difiere entre los segmentos de los usuarios? Qué usuarios deberían de recibir incentivos de prevención? Qué montos de incentivos

Nota: Voy a evaluar las tareas con base en la respuesta a cada pregunta. Como hay algunas preguntas que no tienen una respuesta clara, al final ponderaré de acuerdo al poder predictivo de su modelo vs las respuestas sugeridas.



\newpage

## Datos

Los datos los pueden encontrar en `Cell2Cell.Rdata`. En el archivo `Cell2Cell-Database-Documentation.xlsx` pueden encontrar documentación de la base de datos.

Carguemos los datos
```{r }
load('Cell2Cell.Rdata') %>% as.data.frame()
# file path de archivo
# path_data <- file.path('C:/Users/rsf94/Documents/economia_computacional/tarea_2',
#                       'Cell2Cell.RData')

# renombrar como data
data <- as.data.frame(cell2cell)
rm(cell2cell)
```

### 1. Qué variables tienen missing values? Toma alguna decisión con los missing values. Justifica tu respuesta
```{r,results='asis'}
# Rafa
# tabla resumen de missing values
kable(check_nas(data),booktabs=T, align = 'c',
      col.names = c("Variale", "Cantidad","%"),digits = 2)%>%
  kable_styling(position = "center",
                latex_options="HOLD_position")
```

```{r}
# columnas con NAs
cols_con_nas <- names(which(colSums(is.na(data)) > 0))

df_nas <- data %>% select(all_of(cols_con_nas)) %>% as.data.frame()
summary(df_nas)
```

Lista de las variables con valores faltantes. Todas son numéricas. Podríamos hacer imputación.


## Análisis de missing values (pendiente)

**age_1 y age_2**

Se trata de variables de edad que comienzan a partir de los 18 y para las cuales existe una etiqueta "0" que curiosamente es la moda. Es decir, no conocemos la edad para una gran parte de las observaciones. Podemos aprovechar esta etiqueta y extenderla para tratar los missing values, de tal manera que ahora los NA's tienen la etiqueta "0".
```{r}
summary(factor(data$age1))
summary(factor(data$age2))
data$age1[is.na(data$age1)] <- 0
data$age2[is.na(data$age)] <- 0
```

**phones, models y eqpdays**

En este caso, solo estamos hablando de un missing value por lo que haremos algo sencillo, imputar la moda en phones y models y la media en eqpdays.
```{r}
summary(factor(data$phones))
summary(factor(data$models))
summary((data$eqpdays))

data$phones[is.na(data$phones)] <- mode(factor(data$phones[!is.na(data$phones)]))
data$models[is.na(data$models)] <- mode(factor(data$models[!is.na(data$models)]))
data$eqpdays[is.na(data$eqpdays)]<- mean(data$eqpdays[!is.na(data$eqpdays)])
```

**changem y changer**

**revenue, moe recchrge, directas, overage,roam**

...pendiente

```{r}

# numero de filas con NAs
data[!complete.cases(data),] %>% nrow()

# correlaciones entre variables con NAs
x <- as.data.frame(abs(is.na(data)))
# Extrae las variables que tienen algunas celdas con NAs
y <- x[which(sapply(x, sd) > 0)]
# la sd va a ser positiva para variables que tengan NAs

# Da la correación un valor alto positivo significa que desaparecen juntas.
cor(y)

# Visualización de los NAs
#aggr(data, plot=FALSE, prop=FALSE, numbers=TRUE)

```


Las 216 valores faltantes para revenue, mou, recchrge, directas, overage y roam coinciden.Lo mismo pasa con los 502 valores faltantes de changem y changer, con el valor faltante de phones, models, eqpdays, y con los 1244 valores faltantes de age1 y age2. Además, se puede ver en la matriz que los valores faltantes del primer grupo de variables coincide en un 65% con los valores faltantes de changem y changer. Para estos casos, se tiene valores faltantes en 8 de 68 variables, el 11.7% de las columnas.

Esto en general nos dice que no hay un problema serio de NAs. No obstante, para no perder dicha información, lo mejor sería hacer imputación.

Podemos imputar alguna medida de tendencia central a aquellas variables que parezcan tener una distribución normal o estén concentradas en uno o pocos valores. Para decidir esto, examinamos la distribución de estas variables.

```{r, warning=FALSE}
myhist <- function(yvar){
  ggplot(df_nas, aes_(x=as.name(yvar)))+
    geom_histogram()+
    ggtitle(paste0(as.name(yvar)))+
    xlab("")+
    ylab("")+
    theme(axis.text.y = element_blank())
}
hists<- df_nas %>%
        names() %>%
        lapply(myhist)


grid.arrange(grobs=hists,ncol=4)
```

Es evidente que casi todas estas variables tienen outliers. Por ello, conviene imputar la la mediana, por lo menos para:

 - _revenue_
 - _mou_
 - _recchrge_
 - _changem_
 - _changer_
 - _eqpdays_
 - _directas_
 - _phones_
 - _models_

 
Las primeras seis variables tienen una distribución normal, y las otras tres están altamente concentradas (más del 50% de las observaciones en un valor o entre 0 y 1). Por lo tanto, les imputamos la mediana.

```{r}
# se define una funcion para imputar por valor central
imputar_valor_central <- function(data) {
  # Función para imputar valores centrales, media/mediana en numéricos y moda en categoricos
  # Inputs:
  # data - conjunto de datos
  # colnames - array de las columnas que se desea imputar
  #
  # Outputs
  # dataframe con imputaciones centrales

  var_list <- colnames(data)


  # Filtrar variables numéricas
  data_columnas <- data %>%
    dplyr::select(all_of(var_list)) %>% as.data.frame()
  var_numericas <- dplyr::select_if(data_columnas, is.numeric) %>% names()

  #Imputar
  algas_data_imputacion_central  <-
    data.frame(data) %>%
    # variables numéricas (mediana)
    mutate_at(
      vars(var_numericas),
      funs(ifelse(is.na(.), median(., na.rm = T), .)))

  return(algas_data_imputacion_central)

}

# subset de las variables a las que haremos esta imputacion
df_nas_central <- df_nas %>% dplyr::select(-c(overage,age1,age2))

# se aplica la funcion de imputación
df_nas_central <- imputar_valor_central(df_nas_central)

# revisamos los datos
summary(df_nas_central)

# los sustituimos en la base original
data[,names(df_nas_central)] <- df_nas_central
cols_con_nas2 <- names(which(colSums(is.na(data)) > 0))

```

Por otra parte, las variables age1 y age2, las edades del primer y segundo miembro del hogar, presentan una distribución normal y muchos ceros. Esto nos hace pensar que cuando el valor es desconocido, o bien aparece como cero o como faltante. Por ello, decidimos imputarle a los valores faltantes de estas variables el cero.

```{r}
data$age1[is.na(data$age1)] <- 0
data$age2[is.na(data$age2)] <- 0

```


Por último, revisamos si _overage_ puede imputarse por correlación con otra variable.

```{r}
# Revisemos correlación de estas variables con alguna otra
cors <- cor(data, 
            method = "pearson",
            use = "complete.obs")[,"overage"] %>% as.data.frame() %>%
arrange(desc(.))

head(cors,10)

```

Notamos que _overage_ tiene una correlación mayor a 30% para las variables sin NAs _dropvce, unansvce, mourec, outcalls, incalls, peakvce, opeakvce, dropblk y callwait_.

```{r}

modelo <- lm(overage ~ mourec+peakvce+callwait+outcalls, data)
summary(modelo)

```

### 2. Tabula la distribución de la variable `churn`. Muestra la frecuencia absoluta y relativa. Crees que se debe hacer oversampling/undersamping?
```{r, out.width = '70%',fig.align = "center"}

# tabulación
tabulado <- data %>% group_by(churn) %>% dplyr::summarise(frecuencia_absoluta=n()) %>%
  mutate(frecuencia_relativa = frecuencia_absoluta/sum(frecuencia_absoluta))

kable(tabulado,booktabs=T, align = 'c',
      col.names = c("Churn", "Cantidad","%"),digits = 2)%>%
  kable_styling(position = "center",
                latex_options="HOLD_position")

rm(tabulado)


data$churn <- as.numeric(data$churn)
# frecuencia absoluta
ggplot(data, aes(x=churn))+
  geom_bar(aes(y=..count..,fill=(factor(..x..)),stat="count"))+
  geom_text(aes(label= scales::number(..count..),
                y=..count..),stat="count", vjust=-0.5)+
  labs(title="Distribución de churn",
    subtitle="Frecuencia absoluta",
    fill="Churn")+
  ylab("Frecuencia absoluta")+
  scale_y_continuous(labels=scales::comma,
                     limits=c(0,60000))+
  scale_x_continuous(breaks=c(0,1))+
  theme_bw()+
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank())

# frecuencia relativa
ggplot(data, aes(x=churn))+
  geom_bar(aes(y=..prop.., fill=factor(..x..)),stat="count")+
    geom_text(aes(label= scales::percent(..prop..),
                y=..prop..),stat="count", vjust=-0.5)+
  scale_y_continuous(breaks=seq(0,1, by =0.1),
                     limits=c(0,1))+
  scale_x_continuous(breaks=c(0,1))+

    labs(title="Distribución de churn",
       subtitle="Frecuencia relativa",
       fill="Churn")+
  ylab("Frecuencia relativa")+
  theme_bw()+
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank())

```

Sí, parece que sí se debe hacer algún tipo de remuestreo para tener una base balanceada y que los modelos a estimar tengan mayor poder predictivo.


### 3. (2 pts) Divide tu base en entrenamiento y validación (80/20). Además, considera hacer oversampling (SMOTE) o undersampling. (Tip: Recuerda que el objetivo final es tener muestra ~balanceada en el traning set. En el validation la distribución debe ser la original)

Primero dividimos la base.
```{r}
set.seed(123)

#PARCHE TEMPORAL
#data[is.na(data)] <- 0 # Parche temporal, vuelve 0 los NA


# proporción que queremos de training
training_size <- 0.8

# filas de training
training_rows <- sample(seq_len(nrow(data)),size=floor(training_size*nrow(data)))

#training set
data_training <- data[training_rows,]

#validation set. guardamos la base de características y la variable objetivo por separado
data_validation <- data[-training_rows,-2]
churn_validation <- data[-training_rows,2]

# la muestra está balanceada? --> NO :(
(tabulado <- data_training %>% group_by(churn) %>% dplyr::summarise(frecuencia_absoluta=n()) %>%
  mutate(frecuencia_relativa = frecuencia_absoluta/sum(frecuencia_absoluta)))
```
No está balanceada, aunque sí conserva la proporción de clases de la base original. Procedemos a rebalancear, tenemos 3 estrategias: undersampling, oversampling o una mezcla de ambas.

Cabe mencionar que realizamos el rebalanceo sobre nuestra base de entrenamiento.

```{r undersampling}

# 1. Undersampling

# tamaño de churn==1 en la base de entrenamiento
freq_churn <- data_training %>% filter(churn==1) %>% nrow()


#simplemente reducimos la clase más abundante
undersampling_c0<-  sample_n((data_training %>% filter(churn==0)),
                             size=freq_churn,
                             replace = FALSE)

undersampling<-rbind((data_training %>%
                        filter(churn==1)),undersampling_c0)



```

```{r oversampling}
# 2. oversampling
# Segundo intento, sugiere hacer Synthetic Minority Oversampling Technique (SMOTE) librería smotefamily
# echénle un ojo a: https://rikunert.com/SMOTE_explained
smote <- smotefamily::SMOTE((data_training %>% na.exclude)[,-2], # data
                            (data_training %>% na.exclude)$churn, # class attribute
                            K=10, # number of nearest neighbors
                            dup_size=2 # desired times of synthetic minority instances
                            # over original number of majority instances
                            )


class(data %>% na.exclude)
oversampled <- as.data.frame(smote$data)

# smote guarda la variable de clase como class. se renombra y convierte a numerica
colnames(oversampled)[68] <- "churn"
oversampled$churn <- oversampled$churn %>% as.numeric

# sí está balanceado, aún no entiendo bien los outputs de la función
(tabulado <- oversampled %>% group_by(churn) %>%
    dplyr::summarise(frecuencia_absoluta=n()) %>%
    mutate(frecuencia_relativa = frecuencia_absoluta/sum(frecuencia_absoluta)))


# $data arroja el data frame original + observaciones sintéticas de la minoría
length(as.data.frame(smote$data)$churn)

# syn_data arroja observaciones sintéticas de la minoría
length(as.data.frame(smote$syn_data)$churn)

# resta de ambos nos da el original
length((data_training %>% na.exclude)$churn)


```


```{r under-oversampling}

#Under y over sampling
#para rebalancear de manera más precisa el oversampling, simplemente "podamos" las observaciones sinteticas de tal manera que nos quede una base de datos perfectamente balanceada.

freq_churn_os <- oversampled %>% filter(churn==0) %>% nrow()

#podamos
undersampling_c1<-  sample_n((oversampled %>% filter(churn==1)),
                             size=freq_churn_os,replace = FALSE)

#armamos la base
under_over_sampling<-rbind((oversampled %>% filter(churn==0)),undersampling_c1)

#listo!
(tabulado <- under_over_sampling %>% group_by(churn) %>% dplyr::summarise(frecuencia_absoluta=n()) %>%
    mutate(frecuencia_relativa = frecuencia_absoluta/sum(frecuencia_absoluta)))
```


De esta manera me quedan 3 bases para comparar: undersampling, oversampling y una combinación de ambos. 

Ahora experimentaremos con cada base.

```{r under-oversampling}
data_training_a<-undersampling %>% na.exclude
data_training_b<-oversampled
data_training_c<-under_over_sampling



```



## Model estimation

Pondremos a competir 3 modelos:

1. Cross-Validated LASSO-logit

2. Prune Trees

3. Random Forest

### 4 (2 pts). Estima un cross validated LASSO. Muestra el la gráfica de CV Binomial Deviance vs Complejidad
```{r}
data_training[is.na(data_training)] <- 0 # Parche temporal, vuelve 0 los NA

X <- sparse.model.matrix(~.+0, data = data_training[,-c(1,2)]) # Transformar a sparse matrix la información relevante

cv_lasso <- cv.gamlr(x = X, y = data_training$churn, family = 'binomial', nfold = 5, verb = TRUE) # Estimar el CV LASSO

par(mar=c(5,4,4,2) + 0.1)
plot(cv_lasso) # Gráfico

```
#PARA LAS DIFERENTES BASES DE ENTRENAMIENTO

##A

#Matriz de covariates
Xa <-data_training_a %>% select(-customer,-churn) 

#se quita intercepto
Xa <- sparse.model.matrix(~.+0, data = Xa) 

#vector de Y´s
Ya<-data_training_a$churn 

#CV LASSO
cvlasso_a<-cv.gamlr(x = Xa, y = Ya, verb = T, family = 'binomial', nfold = 5) 

#Grafica
plot(cvlasso_a)

##B

#Matriz de covariates
Xb <-data_training_b %>% select(-customer,-churn) 

#se quita intercepto
Xb <- sparse.model.matrix(~.+0, data = Xb) 

#vector de Y´s
Yb<-data_training_b$churn 

#CV LASSO
cvlasso_b<-cv.gamlr(x = Xb, y = Yb, verb = T, family = 'binomial', nfold = 5) 

#Grafica
plot(cvlasso_b)

##C

#Matriz de covariates
Xc <-data_training_c %>% select(-customer,-churn) 

#se quita intercepto
Xc <- sparse.model.matrix(~.+0, data = Xc) 

#vector de Y´s
Yc<-data_training_c$churn 

#CV LASSO
cvlasso_c<-cv.gamlr(x = Xc, y = Yc, verb = T, family = 'binomial', nfold = 5) 

#Grafica
plot(cvlasso_c)

### 5. Grafica el Lasso de los coeficientes vs la complejidad del modelo.
```{r}
plot(cv_lasso$gamlr, select=FALSE)
```
plot(cvlasso_a$gamlr)
plot(cvlasso_b$gamlr)
plot(cvlasso_c$gamlr)

\newpage

### 6 (2 pts). Cuál es la $\lambda$ resultante? Genera una tabla con los coeficientes que selecciona el CV LASSO. Cuántas variables deja iguales a cero? Cuales son las 3 variables más importantes para predecir el abandono? Da una explicación intuitiva a la última pregunta
```{r}
coef(cv_lasso, select="min") # Coeficientes de CV LASSO
```


```{r}
lambda_id <- colnames(coef(cv_lasso, select="min")) # Identificador para el lambda deseado
cv_lasso$gamlr$lambda[lambda_id] # Valor del lambda deseado

#PARA LAS 3 BASES:

#lambda resultante 
#A
a_lambda<- colnames(coef(cvlasso_a, select="min")) 
cvlasso_a$gamlr$lambda[a_lambda] 

#B
b_lambda<- colnames(coef(cvlasso_b, select="min")) 
cvlasso_b$gamlr$lambda[b_lambda] 

#c
c_lambda<- colnames(coef(cvlasso_c, select="min")) 
cvlasso_a$gamlr$lambda[c_lambda] 

# tabla de coeficientes
coef(cvlasso_a, select="min", k=2, corrected=TRUE) #a 
coef(cvlasso_b, select="min", k=2, corrected=TRUE) #b
coef(cvlasso_c, select="min", k=2, corrected=TRUE) #c
#Para c y b coeficientes en blanco, a final aparecen dos coeficientes classFALSE y classTRUE que no puedo quitar.
```

### 7. Genera un data frame (usando el validation set) que tenga: `customer`, `churn` y las predicciones del LASSO.
```{r}

#Predicciones
y_pred<-predict(cv_lasso, newdata = X, type = 'response')
y_pred<-as.numeric(y_pred)

#A
y_pred_a<-predict(cvlasso_a, newdata = Xa, type = 'response')
y_pred_a<-as.numeric(y_pred_a)

#B
y_pred_b<-predict(cvlasso_b, newdata = Xb, type = 'response')
y_pred_b<-as.numeric(y_pred_b)

#C
y_pred_c<-predict(cvlasso_c, newdata = Xc, type = 'response')
y_pred_c<-as.numeric(y_pred_c)

#dataframe
estandar<-data.frame(data_validation$customer, data_validation$churn, y_pred)

A<-data.frame(data_validation_a$customer, data_validation_a$churn, y_pred_a)

B<-data.frame(data_validation_b$customer, data_validation_b$churn, y_pred_b)

C<-data.frame(data_validation_c$customer, data_validation_c$churn, y_pred_c)

```

### 8. Estima ahora tree. Usa `mindev = 0.05, mincut = 1000` Cuántos nodos terminales salen? Muestra el summary del árbol
```{r}

cat_variables <- c("churn",
                  "children",
                  "credita",
                  "creditaa",
                  "prizmrur",
                  "prizmub",
                  "prizmtwn",
                  "refurb",
                  "webcap",
                  "truck",
                  "rv",
                  "occprof",
                  "occcler",
                  "occcrft",
                  "occstud",
                  "occhmkr",
                  "occret",
                  "occself",
                  "ownrent",
                  "marryun",
                  "marryyes",
                  "mailord",
                  "mailres",
                  "mailflag",
                  "travel",
                  "pcown",
                  "creditcd",
                  "newcelly",
                  "newcelln",
                  "incmiss",
                  "mcycle",
                  "setprcm",
                  "retcall")


round_up_down <- function(x){
  
  return(if_else(x<0.5,as.integer(floor(x)),
          as.integer(ceiling(x))))
  
}

data_training_b[,cat_variables] <- lapply(data_training_b[,cat_variables],round_up_down)
data_training_c[,cat_variables] <- lapply(data_training_c[,cat_variables],round_up_down)


str(data_training_a %>% select(cat_variables) %>% arrange())
summary(data_training_c %>% select(cat_variables) %>% arrange())
View(data_training_c %>% select(cat_variables) %>% arrange())


# hago para los 3 training datasets que tenemos: a,b y c
# b2 es restringiendo variables

#A
tree_control_a <- tree.control(nobs=nrow(data_training_a),
             mincut = 1000,
             mindev = 0.05)


tree_estimation_a <- tree(as.factor(churn) ~ . -customer,
                        data = data_training_a,
                        control = tree_control_a,
                        split = c("gini"))

#B
tree_control_b <- tree.control(nobs=nrow(data_training_b),
             mincut = 1000,
             mindev = 0.05)


tree_estimation_b <- tree(as.factor(churn) ~ . -customer ,
                        data = data_training_b,
                        control = tree_control_b)


tree_estimation_b2 <- tree(as.factor(churn) ~ eqpdays + refurb + changem + months + mou + changer + recchrge + creditcd + setprc + revenue + retcall + marryyes + credita,
                        data = data_training_b)

#C
tree_control_c <- tree.control(nobs=nrow(data_training_c),
             mincut = 1000,
             mindev = 0.05)


tree_estimation_c <- tree(as.factor(churn) ~ . -customer,
                        data = data_training_c,
                        control = tree_control_c)



summary(tree_estimation_a)

summary(tree_estimation_b)
summary(tree_estimation_b2)
summary(tree_estimation_c)

# El a utiliza más variables

```

### 9. Grafica el árbol resultante
```{r}
# me gusta el a

plot(tree_estimation_a)
text(tree_estimation_a,pretty=0)

plot(tree_estimation_b)
text(tree_estimation_b,pretty=0)

plot(tree_estimation_b2)
text(tree_estimation_b2,pretty=0)

plot(tree_estimation_c)
text(tree_estimation_c,pretty=0)


#cross validation y confusionMatrix (opcional)
#data_validation_a$churn <- as.factor(data_validation_a$churn)

#DTpred<- predict(tree_estimation_a,type="class" ,newdata=data_validation_a)
#caret::confusionMatrix(data_validation_a$churn,DTpred)

```

### 10. Poda el árbol usando CV. Muestra el resultado. Grafica Tree Size vs Binomial Deviance. Cuál es el mejor tamaño del árbol? Mejora el Error?
```{r}
cv_tree_a <- cv.tree(tree_estimation_a, K=10)
cv_tree_b <- cv.tree(tree_estimation_b, K=10)
cv_tree_b2 <- cv.tree(tree_estimation_b2, K=10)
cv_tree_c <- cv.tree(tree_estimation_c, K=10)

cv_tree_a
cv_tree_b
cv_tree_b2
cv_tree_c

# Size con menor deviance
min_dev_size_a <- cv_tree_a$size[match(min(cv_tree_a$dev),cv_tree_a$dev)]
min_dev_size_b <-cv_tree_b$size[match(min(cv_tree_b$dev),cv_tree_b$dev)]
min_dev_size_b2 <-cv_tree_b2$size[match(min(cv_tree_b2$dev),cv_tree_b2$dev)]
min_dev_size_c <-cv_tree_c$size[match(min(cv_tree_c$dev),cv_tree_c$dev)]

# Gráfica Tree Size vs. Binomial Deviance

plot_size_dev <- function(cv_tree){

  ggplot(data=as.data.frame(cbind(size=cv_tree$size,dev=cv_tree$dev)),
       aes(x=size,y=dev))+
  geom_point(size=3)+
  labs(title="Deviance against Tree Size")+
  xlab("Tree Size")+
  ylab("Deviance")+
  theme_bw()+
    theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank())

                                  }

plot_size_dev(cv_tree_a)
plot_size_dev(cv_tree_b)
plot_size_dev(cv_tree_b2)
plot_size_dev(cv_tree_c)


```

### 11. Gráfica el árbol final. (Tip: Checa `prune.tree`)
```{r}
tree_cut_a <- prune.tree(tree_estimation_a, best = min_dev_size_a)
tree_cut_b <- prune.tree(tree_estimation_b, best = min_dev_size_b)
tree_cut_b2 <- prune.tree(tree_estimation_b2, best = min_dev_size_b2)
tree_cut_c <- prune.tree(tree_estimation_c, best = min_dev_size_c)

plot(tree_cut_a)
text(tree_cut_a,pretty=0)

plot(tree_cut_b)
text(tree_cut_b,pretty=0)

plot(tree_cut_b2)
text(tree_cut_b2,pretty=0)

plot(tree_cut_c)
text(tree_cut_c,pretty=0)

```

### 12. Genera las predicciones del árbol pruned. Guardalas en la base de predicciones. Guarda el score y la prediccion categorica en la misma data frame donde guardaste las predicciones del LASSO
```{r}

tree_score_predict_a <- predict(tree_cut_a,data=data_validation_a)
tree_class_predict_a <- predict(tree_cut_a,data=data_validation_a,type="class")

tree_score_predict_b <- predict(tree_cut_b,data=data_validation_b)
tree_class_predict_b <- predict(tree_cut_b,data=data_validation_b,type="class")

tree_score_predict_b2 <- predict(tree_cut_b2,data=data_validation_b2)
tree_class_predict_b2 <- predict(tree_cut_b2,data=data_validation_b2,type="class")

tree_score_predict_c <- predict(tree_cut_c,data=data_validation_c)
tree_class_predict_c <- predict(tree_cut_c,data=data_validation_c,type="class")


# unir con base de predicciones


```


### 13 (4pts). Corre un Random Forest ahora. Cuál es la $B$ para la que ya no ganamos mucho más en poder predictivo?

- Corre para `num.trees=100,200,300, 500, 700, 800`

- En cada caso, guarda únicamente el `prediction.error`
```{r}
# eficientar el Random Forest corriendolo en los nodos disponibles del equipo
cl<- detectCores() %>% makeCluster()
cl

# vector con el número de los arboles
trees <- c()
# vector con el prediction error de cada forest
error <- c()

# Estimation. Loop que estima un random forest para distintos numeros de árboles

a<-Sys.time() # para observar el tiempo de estimacion

k <- 1 # iterador
for (i in c(100,200,300,500,700,800)){

  rf<-ranger(churn~.,
             data = data_training_a,
             num.trees = i,
             mtry = (ncol(data_training_a)-1) %>% sqrt() %>% floor(),
             min.node.size = 1,
             splitrule = "gini",
             classification = T,
             )

  trees[k] <- rf$num.trees
  error[k] <- rf$prediction.error

  rf <- NULL
  k <- k + 1
}

treesb <- c()
errorb <- c()

k <- 1 # iterador
for (i in c(100,200,300,500,700,800)){

  rf<-ranger(churn~.,
             data = data_training_b,
             num.trees = i,
             mtry = (ncol(data_training_b)-1) %>% sqrt() %>% floor(),
             min.node.size = 1,
             splitrule = "gini",
             classification = T,
             )

  treesb[k] <- rf$num.trees
  errorb[k] <- rf$prediction.error

  rf <- NULL
  k <- k + 1
}

treesc <- c()
errorc <- c()
k <- 1 # iterador
for (i in c(100,200,300,500,700,800)){

  rf<-ranger(churn~.,
             data = data_training_c,
             num.trees = i,
             mtry = (ncol(data_training_c)-1) %>% sqrt() %>% floor(),
             min.node.size = 1,
             splitrule = "gini",
             classification = T,
             )

  treesc[k] <- rf$num.trees
  errorc[k] <- rf$prediction.error

  rf <- NULL
  k <- k + 1
}

Sys.time() -a
stopCluster(cl)

rf <- data.frame(trees,error)
rfb <- data.frame(treesb,errorb)
rfc <- data.frame(treesc,errorc)
rf
rfb
rfc

```
Parece ser que con una $B=200$, el error de predicción ya no parece reducirse mucho.

### 14. Escoge un random forest para hacer las predicciones. Grafica la importancia de las variables. Interpreta

```{r}
# vuelvo a correr el mejor random forest
cl<- detectCores() %>% makeCluster()
cl
best_rf <- ranger(churn~.,
             data = data_training_a,
             num.trees = 200,
             mtry = (ncol(data_training_a)-1) %>% sqrt() %>% floor(),
             importance = "impurity",
             classification = T,
             )
stopCluster(cl)

# Grafica
df_imp <- data.frame(names=(importance(best_rf) %>%
              names()),importance=(importance(best_rf)))


ggplot(df_imp,aes(x=reorder(names,importance),y=importance)) +
  geom_bar(stat="identity") +
  xlab("Variable")+
  ylab("importancia")+
  coord_flip()

```


### 15. Genera las predicciones OOS para el random forest. Guardalas en la misma data.frame que los otros modelos
```{r}
pred_rf<-predict(best_rf, 
                 data = (data_validation %>% na.exclude))$predictions

eval <-bind_cols((churn_validation %>% na.exclude),
                 pred_rf)

```


### 16 (2pts). Corre el mismo forest pero ahora con `probability = T`. Esto generará predicciones númericas en lugar de categóricas. Genera las predicciones continuas y guardalas en el mismo data frame
```{r}
# vuelvo a correr el mejor random forest, con probability=T
cl<- detectCores() %>% makeCluster()
cl
best_rf2 <- ranger(churn~.,
             data = data_training_a,
             num.trees = 200,
             mtry = (ncol(data_training_a)-1) %>% sqrt() %>% floor(),
             importance = "impurity",
             classification = T,
             probability = T
             )
stopCluster(cl)

# prediccion continua de churn==1
best_rf2$predictions[,1]
```

### 17 (4 pts). Genera graficas de las curvas ROC para los tres modelos. Cual parece ser mejor?
```{r}
# ROC Curve
roc_curve(data = eval, truth = truth, "1")

```


### 18. Genera una tabla con el AUC ROC. Cuál es el mejor modelo ?
```{r}

```

### 19 (2pts). Escoge un punto de corte para generar predicciones categoricas para el LASSO basado en la Curva ROC. Genera las matrices de confusión para cada modelo. Compáralas. Qué tipo de error es mas pernicioso?
```{r}

```

### 20 (2pts). Finalmente, construye una lift table. Esto es, para 20 grupos del score predecido, genera 1) El promedio de las predicciones, 2) el promedio del churn observado. Existe monotonía? El mejor algoritmo es monotónico? (Tip: usa `ntile` para generar los grupos a partir de las predicciones)
```{r}

```


### 21. Concluye. Que estrategia harías con este modelo? Cómo generarías valor a partir de el?
```{r}

```
